{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = '../dataset/PIZZA_train.json'\n",
    "test_path = '../dataset/PIZZA_dev.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(train_path, lines=True)\n",
    "dev = pd.read_json(test_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train.SRC</th>\n",
       "      <th>train.EXR</th>\n",
       "      <th>train.TOP</th>\n",
       "      <th>train.TOP-DECOUPLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2456446</td>\n",
       "      <td>2456446</td>\n",
       "      <td>2456446</td>\n",
       "      <td>2456446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2456446</td>\n",
       "      <td>694346</td>\n",
       "      <td>2456446</td>\n",
       "      <td>1425035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>can i have a large bbq pulled pork</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER three ) (NOT (TOPPI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 train.SRC  \\\n",
       "count                              2456446   \n",
       "unique                             2456446   \n",
       "top     can i have a large bbq pulled pork   \n",
       "freq                                     1   \n",
       "\n",
       "                                                train.EXR  \\\n",
       "count                                             2456446   \n",
       "unique                                             694346   \n",
       "top     (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...   \n",
       "freq                                                 1999   \n",
       "\n",
       "                                                train.TOP  \\\n",
       "count                                             2456446   \n",
       "unique                                            2456446   \n",
       "top     (ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                      train.TOP-DECOUPLED  \n",
       "count                                             2456446  \n",
       "unique                                            1425035  \n",
       "top     (ORDER (PIZZAORDER (NUMBER three ) (NOT (TOPPI...  \n",
       "freq                                                  167  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    694346.000000\n",
       "mean          3.537784\n",
       "std          17.072263\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max        1999.000000\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify unique patterns in 'train.EXR'\n",
    "unique_patterns = df['train.EXR'].value_counts()\n",
    "unique_patterns.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train.SRC</th>\n",
       "      <th>train.EXR</th>\n",
       "      <th>train.TOP</th>\n",
       "      <th>train.TOP-DECOUPLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>720617</td>\n",
       "      <td>720617</td>\n",
       "      <td>720617</td>\n",
       "      <td>720617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>720617</td>\n",
       "      <td>5000</td>\n",
       "      <td>720617</td>\n",
       "      <td>136030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>can i have a large bbq pulled pork</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER three ) (NOT (TOPPI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 train.SRC  \\\n",
       "count                               720617   \n",
       "unique                              720617   \n",
       "top     can i have a large bbq pulled pork   \n",
       "freq                                     1   \n",
       "\n",
       "                                                train.EXR  \\\n",
       "count                                              720617   \n",
       "unique                                               5000   \n",
       "top     (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...   \n",
       "freq                                                 1999   \n",
       "\n",
       "                                                train.TOP  \\\n",
       "count                                              720617   \n",
       "unique                                             720617   \n",
       "top     (ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                      train.TOP-DECOUPLED  \n",
       "count                                              720617  \n",
       "unique                                             136030  \n",
       "top     (ORDER (PIZZAORDER (NUMBER three ) (NOT (TOPPI...  \n",
       "freq                                                  167  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a sample from each pattern\n",
    "reduced_dataset = df[df['train.EXR'].isin(unique_patterns.index[:5000])] # reduce to 5000 patterns\n",
    "reduced_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hima\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2064,  1045,  2031,  1037,  2312, 22861,  4160,  2766, 15960,\n",
      "           102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[  101,  1006,  2344,  1006, 10733,  8551,  2121,  1006,  2193,  1015,\n",
      "          1007,  1006,  2946,  2312,  1007,  1006, 22286, 22861,  4160,  1035,\n",
      "          2766,  1035, 15960,  1007,  1007,  1007,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Example: Using a pre-trained tokenizer like BERT\n",
    "src_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tgt_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "src_text = \"can i have a large bbq pulled pork\"\n",
    "#tgt_text = \"(ORDER can i have (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING bbq pulled pork ) ) )\"\n",
    "tgt_text = \"(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE LARGE ) (TOPPING BBQ_PULLED_PORK ) ) )\"\n",
    "# Tokenize the input and output\n",
    "src_tokens = src_tokenizer(src_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "tgt_tokens = tgt_tokenizer(tgt_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "print(src_tokens)\n",
    "print(tgt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PizzaDataset(Dataset):\n",
    "    def __init__(self, data, src_tokenizer, tgt_tokenizer):\n",
    "        self.data = data\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_text = self.data[\"train.SRC\"][idx]\n",
    "        tgt_text = self.data[\"train.EXR\"][idx]\n",
    "\n",
    "        src_tokens = self.src_tokenizer(src_text, return_tensors=\"pt\", padding=\"max_length\", max_length=50, truncation=True)\n",
    "        tgt_tokens = self.tgt_tokenizer(tgt_text, return_tensors=\"pt\", padding=\"max_length\", max_length=50, truncation=True)\n",
    "\n",
    "        return {\n",
    "            \"src_input_ids\": src_tokens[\"input_ids\"].squeeze(0),\n",
    "            \"src_attention_mask\": src_tokens[\"attention_mask\"].squeeze(0),\n",
    "            \"tgt_input_ids\": tgt_tokens[\"input_ids\"].squeeze(0),\n",
    "            \"tgt_attention_mask\": tgt_tokens[\"attention_mask\"].squeeze(0),\n",
    "        }\n",
    "\n",
    "\n",
    "train_dataset = PizzaDataset(reduced_dataset.reset_index(), src_tokenizer, tgt_tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src_input_ids': tensor([  101,  2283,  2946, 11812, 19116, 11345,  2007,  2137,  8808,  1998,\n",
       "          2007, 18565,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'src_attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]),\n",
       " 'tgt_input_ids': tensor([  101,  1006,  2344,  1006, 10733,  8551,  2121,  1006,  2193,  1015,\n",
       "          1007,  1006,  2946,  2283,  1035,  2946,  1007,  1006,  2806, 11812,\n",
       "          1035, 19116,  1007,  1006, 22286,  2137,  1035,  8808,  1007,  1006,\n",
       "         22286, 23827,  1007,  1007,  1007,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'tgt_attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DevPizzaDataset(Dataset):\n",
    "    def __init__(self, data, src_tokenizer, tgt_tokenizer):\n",
    "        self.data = data\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_text = self.data[\"dev.SRC\"][idx]\n",
    "        tgt_text = self.data[\"dev.EXR\"][idx]\n",
    "\n",
    "        src_tokens = self.src_tokenizer(src_text, return_tensors=\"pt\", padding=\"max_length\", max_length=50, truncation=True)\n",
    "        tgt_tokens = self.tgt_tokenizer(tgt_text, return_tensors=\"pt\", padding=\"max_length\", max_length=50, truncation=True)\n",
    "\n",
    "        return {\n",
    "            \"src_input_ids\": src_tokens[\"input_ids\"].squeeze(0),\n",
    "            \"src_attention_mask\": src_tokens[\"attention_mask\"].squeeze(0),\n",
    "            \"tgt_input_ids\": tgt_tokens[\"input_ids\"].squeeze(0),\n",
    "            \"tgt_attention_mask\": tgt_tokens[\"attention_mask\"].squeeze(0),\n",
    "        }\n",
    "val_dataset = DevPizzaDataset(dev, src_tokenizer, tgt_tokenizer)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src_input_ids': tensor([  101,  1045,  1005,  1040,  2066,  2000,  2344,  1037,  2312, 20949,\n",
       "          1998, 11565, 10733,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'src_attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]),\n",
       " 'tgt_input_ids': tensor([  101,  1006,  2344,  1006, 10733,  8551,  2121,  1006,  2193,  1015,\n",
       "          1007,  1006,  2946,  2312,  1007,  1006, 22286, 24444,  1007,  1006,\n",
       "         22286, 23582,  1007,  1007,  1007,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'tgt_attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.__getitem__(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset.__getitem__(3)['src_input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLSTM-Based Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BiLSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, vocab_size, num_layers=1):\n",
    "        super(BiLSTMEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = True\n",
    "        self.num_directions = 2 if self.bidirectional else 1\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers,\n",
    "                            bidirectional=self.bidirectional, batch_first=True)\n",
    "\n",
    "    def forward(self, src, src_lengths):\n",
    "        embedded = self.embedding(src)  # (batch_size, seq_len, embedding_dim)\n",
    "\n",
    "        # Initialize hidden and cell states\n",
    "        batch_size = src.size(0)\n",
    "        h0 = torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_dim).to(src.device)\n",
    "        c0 = torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_dim).to(src.device)\n",
    "\n",
    "        # Pack the sequences for the LSTM\n",
    "        src_lengths = src_lengths.cpu()  # Move lengths to CPU\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, src_lengths, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        # Pass through the LSTM\n",
    "        outputs, (hidden, cell) = self.lstm(packed, (h0, c0))\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "\n",
    "        # Return all hidden states (both forward and backward)\n",
    "        return outputs, hidden, cell\n",
    "\n",
    "\n",
    "\n",
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim, vocab_size, num_layers=1):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(1)  # (batch_size, 1)\n",
    "        embedded = self.embedding(input)  # (batch_size, 1, embedding_dim)\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(1))  # (batch_size, vocab_size)\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, src_lengths, tgt, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.shape[0]\n",
    "        tgt_len = tgt.shape[1]\n",
    "        tgt_vocab_size = self.decoder.fc_out.out_features\n",
    "\n",
    "        # Tensor to store decoder outputs\n",
    "        outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n",
    "\n",
    "        # Encode source sequence\n",
    "        encoder_outputs, hidden, cell = self.encoder(src, src_lengths)\n",
    "\n",
    "        # Reshape hidden and cell states for the decoder\n",
    "        hidden = hidden.view(self.encoder.num_layers, batch_size, -1)\n",
    "        cell = cell.view(self.encoder.num_layers, batch_size, -1)\n",
    "\n",
    "        # First input to the decoder is the <sos> token\n",
    "        input = tgt[:, 0]\n",
    "\n",
    "        for t in range(1, tgt_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[:, t, :] = output\n",
    "            # Decide whether to use teacher forcing\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)  # Get the highest predicted token\n",
    "            input = tgt[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, path=\"checkpoint.pth\"):\n",
    "    checkpoint = {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f\"Checkpoint saved at epoch {epoch}.\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, path=\"checkpoint.pth\"):\n",
    "\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    epoch = checkpoint[\"epoch\"]\n",
    "    print(f\"Checkpoint loaded. Resuming from epoch {epoch}.\")\n",
    "    return epoch\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, optimizer, criterion, device, checkpoint_path):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    total_batches = len(dataloader)\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training Progress\", unit=\"batch\", leave=True)\n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        src = batch[\"src_input_ids\"].to(device)\n",
    "        src_lengths = (batch[\"src_attention_mask\"] != 0).sum(dim=1).cpu()\n",
    "        tgt = batch[\"tgt_input_ids\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, src_lengths, tgt)\n",
    "        # Reshape for loss computation\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        tgt = tgt[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, tgt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        avg_loss = epoch_loss / (batch_idx + 1)\n",
    "        progress_bar.set_description(f\"Training Progress: Batch {batch_idx + 1}/{total_batches}, Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            src = batch[\"src_input_ids\"].to(device)\n",
    "            src_lengths = (batch[\"src_attention_mask\"] != 0).sum(dim=1).to(device)\n",
    "            tgt = batch[\"tgt_input_ids\"].to(device)\n",
    "\n",
    "            output = model(src, src_lengths, tgt, teacher_forcing_ratio=0)  # No teacher forcing during evaluation\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            tgt = tgt[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, tgt)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token-Level Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_accuracy(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total_tokens = 0\n",
    "    correct_tokens = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            src = batch[\"src_input_ids\"].to(device)\n",
    "            src_lengths = (batch[\"src_attention_mask\"] != 0).sum(dim=1).to(device)\n",
    "            tgt = batch[\"tgt_input_ids\"].to(device)\n",
    "\n",
    "            output = model(src, src_lengths, tgt, teacher_forcing_ratio=0)  # No teacher forcing during evaluation\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)  # Reshape for token comparison\n",
    "            tgt = tgt[:, 1:].reshape(-1)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(output, tgt)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            predictions = output.argmax(dim=1)  # Get the index of the max log-probability\n",
    "            correct_tokens += (predictions == tgt).sum().item()\n",
    "            total_tokens += tgt.size(0)\n",
    "\n",
    "    accuracy = correct_tokens / total_tokens if total_tokens > 0 else 0\n",
    "    return epoch_loss / len(dataloader), accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence-Level Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_sequence_accuracy(model, dataloader, criterion, device, tokenizer):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total_sequences = 0\n",
    "    correct_sequences = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            src = batch[\"src_input_ids\"].to(device)\n",
    "            src_lengths = (batch[\"src_attention_mask\"] != 0).sum(dim=1).to(device)\n",
    "            tgt = batch[\"tgt_input_ids\"].to(device)\n",
    "\n",
    "            output = model(src, src_lengths, tgt, teacher_forcing_ratio=0)  # No teacher forcing during evaluation\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.argmax(dim=-1)  # Get the predicted tokens\n",
    "\n",
    "            # Decode sequences for comparison\n",
    "            predicted_sequences = [tokenizer.decode(seq, skip_special_tokens=True) for seq in output]\n",
    "            target_sequences = [tokenizer.decode(seq, skip_special_tokens=True) for seq in tgt]\n",
    "\n",
    "            # Calculate sequence accuracy\n",
    "            for pred, tgt in zip(predicted_sequences, target_sequences):\n",
    "                if pred == tgt:\n",
    "                    correct_sequences += 1\n",
    "                total_sequences += 1\n",
    "\n",
    "    sequence_accuracy = correct_sequences / total_sequences if total_sequences > 0 else 0\n",
    "    return epoch_loss / len(dataloader), sequence_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: Batch 11260/11260, Avg Loss: 0.5588: 100%|██████████| 11260/11260 [2:50:46<00:00,  1.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.559, Val Loss: 5.866\n",
      "Checkpoint saved at epoch 1.\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(src_tokenizer.vocab)\n",
    "OUTPUT_DIM = len(tgt_tokenizer.vocab)\n",
    "EMBEDDING_DIM = 256\n",
    "HIDDEN_DIM = 512\n",
    "NUM_LAYERS = 2\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "encoder = BiLSTMEncoder(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, INPUT_DIM, NUM_LAYERS).to(DEVICE)\n",
    "decoder = LSTMDecoder(EMBEDDING_DIM, HIDDEN_DIM * 2, OUTPUT_DIM, OUTPUT_DIM, NUM_LAYERS).to(DEVICE)\n",
    "model = Seq2Seq(encoder, decoder, DEVICE).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tgt_tokenizer.pad_token_id)\n",
    "\n",
    "checkpoint_path = \"checkpoint_1.pth\"\n",
    "start_epoch = 1\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs + 1):\n",
    "    epoch_loss = 0\n",
    "    total_batches = len(train_dataloader)\n",
    "    train_loss = train_model(model, train_dataloader, optimizer, criterion, DEVICE, checkpoint_path)\n",
    "    val_loss = evaluate_model(model, val_dataloader, criterion, DEVICE)\n",
    "    print(f\"Train Loss: {train_loss:.3f}, Val Loss: {val_loss:.3f}\")\n",
    "    save_checkpoint(model, optimizer, epoch, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.866480429967244, 0.228477597935726)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_with_accuracy(model, val_dataloader, criterion, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded. Resuming from epoch {'src_input_ids': tensor([[  101,  2064,  1045,  ...,     0,     0,     0],\n",
      "        [  101,  1045,  1005,  ...,     0,     0,     0],\n",
      "        [  101,  1045,  2215,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1045,  1005,  ...,     0,     0,     0],\n",
      "        [  101,  2176, 10733,  ...,     0,     0,     0],\n",
      "        [  101,  2176, 10733,  ...,     0,     0,     0]]), 'src_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'tgt_input_ids': tensor([[  101,  1006,  2344,  ...,     0,     0,     0],\n",
      "        [  101,  1006,  2344,  ...,     0,     0,     0],\n",
      "        [  101,  1006,  2344,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1006,  2344,  ...,   102,     0,     0],\n",
      "        [  101,  1006,  2344,  ..., 13874, 14580,   102],\n",
      "        [  101,  1006,  2344,  ...,     0,     0,     0]]), 'tgt_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/38382 [00:24<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     load_checkpoint(model, optimizer, checkpoint_path)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model from the loaded epoch\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m train_model(\n\u001b[0;32m      8\u001b[0m     model,\n\u001b[0;32m      9\u001b[0m     train_dataloader,\n\u001b[0;32m     10\u001b[0m     optimizer,\n\u001b[0;32m     11\u001b[0m     criterion,\n\u001b[0;32m     12\u001b[0m     DEVICE,\n\u001b[0;32m     13\u001b[0m     checkpoint_path\u001b[38;5;241m=\u001b[39mcheckpoint_path\n\u001b[0;32m     14\u001b[0m )\n",
      "Cell \u001b[1;32mIn[24], line 126\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, optimizer, criterion, device, checkpoint_path)\u001b[0m\n\u001b[0;32m    124\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    125\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 126\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    127\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m epoch_loss \u001b[38;5;241m/\u001b[39m (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m :\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    load_checkpoint(model, optimizer, checkpoint_path)\n",
    "\n",
    "# Train the model from the loaded epoch\n",
    "train_model(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    DEVICE,\n",
    "    checkpoint_path=checkpoint_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, src, src_lengths, max_len=50):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden, cell = model.encoder(src, src_lengths)\n",
    "        input = torch.tensor([tgt_tokenizer.bos_token_id]).to(model.device)\n",
    "\n",
    "        outputs = []\n",
    "        for _ in range(max_len):\n",
    "            output, hidden, cell = model.decoder(input, hidden, cell)\n",
    "            top1 = output.argmax(1).item()\n",
    "            outputs.append(top1)\n",
    "            if top1 == tgt_tokenizer.eos_token_id:\n",
    "                break\n",
    "            input = torch.tensor([top1]).to(model.device)\n",
    "\n",
    "        return tgt_tokenizer.decode(outputs, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    print(f\"Model loaded from {path}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, \"../weights/transformer_Bilstm.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
