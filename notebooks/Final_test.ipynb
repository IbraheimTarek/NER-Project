{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def tokenize_top(s):\n",
    "    # Extract tokens: parentheses or sequences of non-whitespace, non-parenthesis characters.\n",
    "    tokens = re.findall(r'\\(|\\)|[^\\s()]+', s)\n",
    "    return tokens\n",
    "\n",
    "def tokenize_input(s):\n",
    "    return s.split()\n",
    "\n",
    "def tokens_to_ints(tokens, vocab):\n",
    "    # map the tokens to integers from vocab\n",
    "    # if the token is not in the vocab, use the index of the unknown token\n",
    "    return [vocab.get(token, vocab['<UNK>']) for token in tokens]\n",
    "\n",
    "def parse_tokens(tokens):\n",
    "    # Parse tokens into a nested list structure\n",
    "    stack = []\n",
    "    current_list = []\n",
    "    for token in tokens:\n",
    "        if token == '(':\n",
    "            stack.append(current_list)\n",
    "            current_list = []\n",
    "        elif token == ')':\n",
    "            finished = current_list\n",
    "            current_list = stack.pop()\n",
    "            current_list.append(finished)\n",
    "        else:\n",
    "            current_list.append(token)\n",
    "    return current_list\n",
    "\n",
    "def normalize_structure(tree):\n",
    "    if not isinstance(tree, list):\n",
    "        return None\n",
    "\n",
    "    def is_key(token):\n",
    "        return token in [\n",
    "            \"ORDER\", \"PIZZAORDER\", \"DRINKORDER\", \"NUMBER\", \"SIZE\", \"STYLE\", \"TOPPING\",\n",
    "            \"COMPLEX_TOPPING\", \"QUANTITY\", \"VOLUME\", \"DRINKTYPE\", \"CONTAINERTYPE\", \"NOT\"\n",
    "        ]\n",
    "\n",
    "    # Clean the list by keeping sublists and tokens as-is for further analysis\n",
    "    cleaned = []\n",
    "    for el in tree:\n",
    "        cleaned.append(el)\n",
    "\n",
    "    if len(cleaned) > 0 and isinstance(cleaned[0], str) and is_key(cleaned[0]):\n",
    "        key = cleaned[0]\n",
    "        if key == \"ORDER\":\n",
    "            pizzaorders = []\n",
    "            drinkorders = []\n",
    "            for sub in cleaned[1:]:\n",
    "                node = normalize_structure(sub)\n",
    "                if isinstance(node, dict):\n",
    "                    if \"PIZZAORDER\" in node:\n",
    "                        if isinstance(node[\"PIZZAORDER\"], list):\n",
    "                            pizzaorders.extend(node[\"PIZZAORDER\"])\n",
    "                        else:\n",
    "                            pizzaorders.append(node[\"PIZZAORDER\"])\n",
    "                    if \"DRINKORDER\" in node:\n",
    "                        if isinstance(node[\"DRINKORDER\"], list):\n",
    "                            drinkorders.extend(node[\"DRINKORDER\"])\n",
    "                        else:\n",
    "                            drinkorders.append(node[\"DRINKORDER\"])\n",
    "                    if node.get(\"TYPE\") == \"PIZZAORDER\":\n",
    "                        pizzaorders.append(node)\n",
    "                    if node.get(\"TYPE\") == \"DRINKORDER\":\n",
    "                        drinkorders.append(node)\n",
    "            result = {}\n",
    "            if pizzaorders:\n",
    "                result[\"PIZZAORDER\"] = pizzaorders\n",
    "            if drinkorders:\n",
    "                result[\"DRINKORDER\"] = drinkorders\n",
    "            if result:\n",
    "                return {\"ORDER\": result}\n",
    "            else:\n",
    "                return {}\n",
    "\n",
    "        elif key == \"PIZZAORDER\":\n",
    "            number = None\n",
    "            size = None\n",
    "            style = None\n",
    "            toppings = []\n",
    "            for sub in cleaned[1:]:\n",
    "                node = normalize_structure(sub)\n",
    "                if isinstance(node, dict):\n",
    "                    t = node.get(\"TYPE\")\n",
    "                    if t == \"NUMBER\":\n",
    "                        number = node[\"VALUE\"]\n",
    "                    elif t == \"SIZE\":\n",
    "                        size = node[\"VALUE\"]\n",
    "                    elif t == \"STYLE\":\n",
    "                        style = node[\"VALUE\"]\n",
    "                    elif t == \"TOPPING\":\n",
    "                        toppings.append(node)\n",
    "            result = {}\n",
    "            if number is not None:\n",
    "                result[\"NUMBER\"] = number\n",
    "            if size is not None:\n",
    "                result[\"SIZE\"] = size\n",
    "            if style is not None:\n",
    "                result[\"STYLE\"] = style\n",
    "            if toppings:\n",
    "                result[\"AllTopping\"] = toppings\n",
    "            # Mark type internally, will remove later\n",
    "            result[\"TYPE\"] = \"PIZZAORDER\"\n",
    "            return result\n",
    "\n",
    "        elif key == \"DRINKORDER\":\n",
    "            number = None\n",
    "            volume = None\n",
    "            drinktype = None\n",
    "            containertype = None\n",
    "            for sub in cleaned[1:]:\n",
    "                node = normalize_structure(sub)\n",
    "                if isinstance(node, dict):\n",
    "                    t = node.get(\"TYPE\")\n",
    "                    if t == \"NUMBER\":\n",
    "                        number = node[\"VALUE\"]\n",
    "                    elif t == \"VOLUME\" or t == \"SIZE\":\n",
    "                        volume = node[\"VALUE\"]\n",
    "                    elif t == \"DRINKTYPE\":\n",
    "                        drinktype = node[\"VALUE\"]\n",
    "                    elif t == \"CONTAINERTYPE\":\n",
    "                        containertype = node[\"VALUE\"]\n",
    "            result = {}\n",
    "            if number is not None:\n",
    "                result[\"NUMBER\"] = number\n",
    "            if volume is not None:\n",
    "                result[\"SIZE\"] = volume\n",
    "            if drinktype is not None:\n",
    "                result[\"DRINKTYPE\"] = drinktype\n",
    "            if containertype is not None:\n",
    "                result[\"CONTAINERTYPE\"] = containertype\n",
    "            result[\"TYPE\"] = \"DRINKORDER\"\n",
    "            return result\n",
    "\n",
    "        elif key in [\"NUMBER\",\"SIZE\",\"STYLE\",\"VOLUME\",\"DRINKTYPE\",\"CONTAINERTYPE\",\"QUANTITY\"]:\n",
    "            values = []\n",
    "            for el in cleaned[1:]:\n",
    "                if isinstance(el, str):\n",
    "                    values.append(el)\n",
    "            value_str = \" \".join(values).strip()\n",
    "            return {\n",
    "                \"TYPE\": key,\n",
    "                \"VALUE\": value_str\n",
    "            }\n",
    "\n",
    "        elif key == \"TOPPING\":\n",
    "            values = []\n",
    "            for el in cleaned[1:]:\n",
    "                if isinstance(el, str):\n",
    "                    values.append(el)\n",
    "            topping_str = \" \".join(values).strip()\n",
    "            return {\n",
    "                \"TYPE\": \"TOPPING\",\n",
    "                \"NOT\": False,\n",
    "                \"Quantity\": None,\n",
    "                \"Topping\": topping_str\n",
    "            }\n",
    "\n",
    "        elif key == \"COMPLEX_TOPPING\":\n",
    "            quantity = None\n",
    "            topping = None\n",
    "            for sub in cleaned[1:]:\n",
    "                node = normalize_structure(sub)\n",
    "                if isinstance(node, dict):\n",
    "                    t = node.get(\"TYPE\")\n",
    "                    if t == \"QUANTITY\":\n",
    "                        quantity = node[\"VALUE\"]\n",
    "                    elif t == \"TOPPING\":\n",
    "                        topping = node[\"Topping\"]\n",
    "            return {\n",
    "                \"TYPE\": \"TOPPING\",\n",
    "                \"NOT\": False,\n",
    "                \"Quantity\": quantity,\n",
    "                \"Topping\": topping\n",
    "            }\n",
    "\n",
    "        elif key == \"NOT\":\n",
    "            for sub in cleaned[1:]:\n",
    "                node = normalize_structure(sub)\n",
    "                if isinstance(node, dict) and node.get(\"TYPE\") == \"TOPPING\":\n",
    "                    node[\"NOT\"] = True\n",
    "                    if \"Quantity\" not in node:\n",
    "                        node[\"Quantity\"] = None\n",
    "                    return node\n",
    "            return None\n",
    "\n",
    "    else:\n",
    "        # Try to parse sublists and combine orders found\n",
    "        combined_order = {\"PIZZAORDER\": [], \"DRINKORDER\": []}\n",
    "        found_order = False\n",
    "\n",
    "        for el in cleaned:\n",
    "            node = normalize_structure(el)\n",
    "            if isinstance(node, dict):\n",
    "                if \"ORDER\" in node:\n",
    "                    found_order = True\n",
    "                    order_node = node[\"ORDER\"]\n",
    "                    if \"PIZZAORDER\" in order_node:\n",
    "                        combined_order[\"PIZZAORDER\"].extend(order_node[\"PIZZAORDER\"])\n",
    "                    if \"DRINKORDER\" in order_node:\n",
    "                        combined_order[\"DRINKORDER\"].extend(order_node[\"DRINKORDER\"])\n",
    "                elif node.get(\"TYPE\") == \"PIZZAORDER\":\n",
    "                    found_order = True\n",
    "                    combined_order[\"PIZZAORDER\"].append(node)\n",
    "                elif node.get(\"TYPE\") == \"DRINKORDER\":\n",
    "                    found_order = True\n",
    "                    combined_order[\"DRINKORDER\"].append(node)\n",
    "\n",
    "        if found_order:\n",
    "            final = {}\n",
    "            if combined_order[\"PIZZAORDER\"]:\n",
    "                final[\"PIZZAORDER\"] = combined_order[\"PIZZAORDER\"]\n",
    "            if combined_order[\"DRINKORDER\"]:\n",
    "                final[\"DRINKORDER\"] = combined_order[\"DRINKORDER\"]\n",
    "            return {\"ORDER\": final} if final else {}\n",
    "\n",
    "        return None\n",
    "    \n",
    "def normalize_structure2(tree):\n",
    "    if not isinstance(tree, list):\n",
    "        return None\n",
    "\n",
    "    def is_key(token):\n",
    "        return token in [\n",
    "            \"ORDER\", \"PIZZAORDER\", \"DRINKORDER\", \"NUMBER\", \"SIZE\", \"STYLE\", \"TOPPING\",\n",
    "            \"QUANTITY\", \"VOLUME\", \"DRINKTYPE\", \"CONTAINERTYPE\", \"NOT\", \"COMPLEX_TOPPING\"\n",
    "        ]\n",
    "\n",
    "    def remove_empty_orders(data):\n",
    "        \"\"\"\n",
    "        Recursively remove empty PIZZAORDER or DRINKORDER nodes, but keep other fields.\n",
    "        \"\"\"\n",
    "        if isinstance(data, dict):\n",
    "            filtered = {}\n",
    "            for k, v in data.items():\n",
    "                if k in [\"PIZZAORDER\", \"DRINKORDER\"] and not v:  # Remove empty orders\n",
    "                    continue\n",
    "                filtered[k] = remove_empty_orders(v)\n",
    "            return filtered\n",
    "        elif isinstance(data, list):\n",
    "            return [remove_empty_orders(item) for item in data]\n",
    "        else:\n",
    "            return data\n",
    "\n",
    "    # Normalize tree\n",
    "    cleaned = []\n",
    "    for el in tree:\n",
    "        cleaned.append(el)\n",
    "\n",
    "    if len(cleaned) > 0 and isinstance(cleaned[0], str) and is_key(cleaned[0]):\n",
    "        key = cleaned[0]\n",
    "        if key == \"ORDER\":\n",
    "            pizzaorders = []\n",
    "            drinkorders = []\n",
    "            for sub in cleaned[1:]:\n",
    "                node = normalize_structure(sub)\n",
    "                if isinstance(node, dict):\n",
    "                    if \"PIZZAORDER\" in node:\n",
    "                        pizzaorders.append(node[\"PIZZAORDER\"])\n",
    "                    elif \"DRINKORDER\" in node:\n",
    "                        drinkorders.append(node[\"DRINKORDER\"])\n",
    "            result = {}\n",
    "            if pizzaorders:\n",
    "                result[\"PIZZAORDER\"] = pizzaorders\n",
    "            if drinkorders:\n",
    "                result[\"DRINKORDER\"] = drinkorders\n",
    "            return remove_empty_orders({\"ORDER\": result}) if result else {}\n",
    "\n",
    "        elif key == \"PIZZAORDER\":\n",
    "            number = None\n",
    "            size = None\n",
    "            style = None\n",
    "            toppings = []\n",
    "            pending_quantity = None  # Track unassigned QUANTITY\n",
    "            for sub in cleaned[1:]:\n",
    "                node = normalize_structure(sub)\n",
    "                if isinstance(node, dict):\n",
    "                    t = node.get(\"TYPE\")\n",
    "                    if t == \"NUMBER\":\n",
    "                        number = node[\"VALUE\"]\n",
    "                    elif t == \"SIZE\":\n",
    "                        size = node[\"VALUE\"]\n",
    "                    elif t == \"STYLE\":\n",
    "                        style = node[\"VALUE\"]\n",
    "                    elif t == \"QUANTITY\":\n",
    "                        pending_quantity = node[\"VALUE\"]  # Store the QUANTITY\n",
    "                    elif t == \"TOPPING\":\n",
    "                        # Attach pending QUANTITY to the current TOPPING\n",
    "                        if pending_quantity:\n",
    "                            node[\"Quantity\"] = pending_quantity\n",
    "                            pending_quantity = None\n",
    "                        toppings.append(node)\n",
    "                    elif t == \"COMPLEX_TOPPING\":\n",
    "                        for topping in node[\"AllTopping\"]:\n",
    "                            toppings.append(topping)\n",
    "            result = {}\n",
    "            if number is not None:\n",
    "                result[\"NUMBER\"] = number\n",
    "            if size is not None:\n",
    "                result[\"SIZE\"] = size\n",
    "            if style is not None:\n",
    "                result[\"STYLE\"] = style\n",
    "            if toppings:\n",
    "                result[\"AllTopping\"] = toppings\n",
    "            return remove_empty_orders({\"PIZZAORDER\": result})\n",
    "\n",
    "        elif key in [\"NUMBER\", \"SIZE\", \"STYLE\", \"VOLUME\", \"DRINKTYPE\", \"CONTAINERTYPE\", \"QUANTITY\"]:\n",
    "            values = []\n",
    "            for el in cleaned[1:]:\n",
    "                if isinstance(el, str):\n",
    "                    values.append(el)\n",
    "            value_str = \" \".join(values).strip()\n",
    "            return {\"TYPE\": key, \"VALUE\": value_str}\n",
    "\n",
    "        elif key == \"TOPPING\":\n",
    "            values = []\n",
    "            for el in cleaned[1:]:\n",
    "                if isinstance(el, str):\n",
    "                    values.append(el)\n",
    "            topping_str = \" \".join(values).strip()\n",
    "            return {\"TYPE\": \"TOPPING\", \"NOT\": False, \"Quantity\": None, \"Topping\": topping_str}\n",
    "\n",
    "        elif key == \"NOT\":\n",
    "            for sub in cleaned[1:]:\n",
    "                node = normalize_structure(sub)\n",
    "                if isinstance(node, dict) and node.get(\"TYPE\") == \"TOPPING\":\n",
    "                    node[\"NOT\"] = True\n",
    "                    if \"Quantity\" not in node:\n",
    "                        node[\"Quantity\"] = None\n",
    "                    return node\n",
    "            return None\n",
    "\n",
    "        elif key == \"COMPLEX_TOPPING\":\n",
    "            quantity = None\n",
    "            topping = None\n",
    "            for sub in cleaned[1:]:\n",
    "                node = normalize_structure(sub)\n",
    "                if isinstance(node, dict):\n",
    "                    if node.get(\"TYPE\") == \"QUANTITY\":\n",
    "                        quantity = node[\"VALUE\"]\n",
    "                    elif node.get(\"TYPE\") == \"TOPPING\":\n",
    "                        topping = node[\"Topping\"]\n",
    "            if topping:\n",
    "                return {\"TYPE\": \"COMPLEX_TOPPING\", \"AllTopping\": [{\"Quantity\": quantity, \"Topping\": topping}]}\n",
    "            return None\n",
    "\n",
    "    else:\n",
    "        # Handle nested lists without specific keys\n",
    "        combined_order = {\"PIZZAORDER\": [], \"DRINKORDER\": []}\n",
    "        for el in cleaned:\n",
    "            node = normalize_structure(el)\n",
    "            if isinstance(node, dict):\n",
    "                if \"ORDER\" in node:\n",
    "                    order = node[\"ORDER\"]\n",
    "                    if \"PIZZAORDER\" in order:\n",
    "                        combined_order[\"PIZZAORDER\"].extend(order[\"PIZZAORDER\"])\n",
    "                    if \"DRINKORDER\" in order:\n",
    "                        combined_order[\"DRINKORDER\"].extend(order[\"DRINKORDER\"])\n",
    "                elif node.get(\"TYPE\") == \"PIZZAORDER\":\n",
    "                    combined_order[\"PIZZAORDER\"].append(node)\n",
    "                elif node.get(\"TYPE\") == \"DRINKORDER\":\n",
    "                    combined_order[\"DRINKORDER\"].append(node)\n",
    "        return remove_empty_orders({\"ORDER\": combined_order}) if combined_order[\"PIZZAORDER\"] or combined_order[\"DRINKORDER\"] else None\n",
    "\n",
    "def remove_type_keys(obj):\n",
    "    # Recursively remove \"TYPE\" keys from all dictionaries\n",
    "    if isinstance(obj, dict):\n",
    "        obj.pop(\"TYPE\", None)\n",
    "        for k, v in obj.items():\n",
    "            remove_type_keys(v)\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            remove_type_keys(item)\n",
    "\n",
    "\n",
    "def preprocess_top(text):\n",
    "    print(text)\n",
    "    tokens = tokenize_top(text)\n",
    "    parsed = parse_tokens(tokens)\n",
    "    result = normalize_structure2(parsed)\n",
    "    remove_type_keys(result)\n",
    "    return result\n",
    "\n",
    "def preprocess_true_top(text):\n",
    "    print(text)\n",
    "    tokens = tokenize_top(text)\n",
    "    parsed = parse_tokens(tokens)\n",
    "    result = normalize_structure(parsed)\n",
    "    remove_type_keys(result)\n",
    "    return result\n",
    "\n",
    "input_str = \"(ORDER potato potato junior (PIZZAORDER (NUMBER one) (SIZE large) (STYLE thin crust) (TOPPING hot cheese) (TOPPING pepperoni) ) (PIZZAORDER (NUMBER two) (SIZE medium) (STYLE deep dish) (NOT (TOPPING mushrooms) ) (NOT (COMPLEX_TOPPING (QUANTITY extra) (TOPPING olives) ) ) ) (DRINKORDER (NUMBER five) (VOLUME one liter) (DRINKTYPE lemon ice tea) (CONTAINERTYPE bottles)) (DRINKORDER (NUMBER three) (VOLUME two liters) (DRINKTYPE cola) (CONTAINERTYPE cans)) (DRINKORDER (NUMBER three) (VOLUME two liters) (DRINKTYPE cola) (CONTAINERTYPE cans) ) )\"\n",
    "\n",
    "result = preprocess_top(input_str)\n",
    "result2 = preprocess_true_top(input_str)\n",
    "print(result == result2)\n",
    "\n",
    "print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def load_vocab():\n",
    "    # loads the vocab from the text file \"vocab.txt\" and then swaps the key value pairs\n",
    "    with open(\"../dataset2/vocab.txt\", \"r\") as f:\n",
    "        vocab = f.readlines()\n",
    "    # remove any commas and single quotes\n",
    "    vocab = [v.replace(\",\", \"\").replace(\"'\", \"\") for v in vocab]\n",
    "    vocab = {v.split(\":\")[0].strip():int(v.split(\":\")[1].strip()) for v in vocab}\n",
    "    return vocab\n",
    "\n",
    "vocab = load_vocab()\n",
    "print(vocab)\n",
    "\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, num_layers=3, dropout=0.5):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        self.bilstm_1 = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc2 = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embedding layer\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        # BiLSTM layer\n",
    "        lstm_out, _ = self.bilstm_1(embedded)\n",
    "\n",
    "        output = self.fc2(lstm_out)\n",
    "        return F.log_softmax(output, dim=-1)\n",
    "\n",
    "input_dim = len(vocab) \n",
    "embedding_dim = 128  # len(vocab)\n",
    "hidden_dim = 128  # Hidden state size for LSTM          first was 256 for batch norm 150\n",
    "output_dim1 = 6  # Number of output classes\n",
    "output_dim2 = 40  # Number of output classes\n",
    "num_layers = 2  # Number of BiLSTM layers\n",
    "dropout = 0.3  # Dropout probability\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_1 = BiLSTMModel(input_dim, embedding_dim, hidden_dim, output_dim1, num_layers, dropout).to(device)\n",
    "model_2 = BiLSTMModel(input_dim, embedding_dim, hidden_dim, output_dim2, num_layers, dropout).to(device)\n",
    "\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    print(f\"Model loaded from {path}\")\n",
    "    return model\n",
    "\n",
    "# load the 2 models\n",
    "load_model(model_1, \"../weights/Bilstm_order_sequence.pt\")\n",
    "load_model(model_2, \"../weights/Bilstm_model2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "# Label maps for the models\n",
    "MODEL_1_LABEL_MAP = {\n",
    "    \"B-PIZZAORDER\": 1,\n",
    "    \"I-PIZZAORDER\": 2,\n",
    "    \"B-DRINKORDER\": 3,\n",
    "    \"I-DRINKORDER\": 4,\n",
    "    \"O\": 5\n",
    "}\n",
    "\n",
    "MODEL_2_LABEL_MAP = {\n",
    "    'B-DRINKTYPE': 1, 'I-DRINKTYPE': 2,\n",
    "    'B-SIZE': 3, 'I-SIZE': 4,\n",
    "    'B-NUMBER': 5, 'I-NUMBER': 6,\n",
    "    'B-CONTAINERTYPE': 7, 'I-CONTAINERTYPE': 8,\n",
    "    'B-COMPLEX_TOPPING': 9, 'I-COMPLEX_TOPPING': 10,\n",
    "    'B-TOPPING': 11, 'I-TOPPING': 12,\n",
    "    'B-NEG_TOPPING': 13, 'I-NEG_TOPPING': 14,\n",
    "    'B-NEG_STYLE': 15, 'I-NEG_STYLE': 16,\n",
    "    'B-STYLE': 17, 'I-STYLE': 18,\n",
    "    'B-QUANTITY': 19, 'I-QUANTITY': 20,\n",
    "    'O': 21\n",
    "}\n",
    "\n",
    "# Function to apply both models and get the TOP_DECOUPLED format\n",
    "def process_entry(entry):\n",
    "    src_text = entry[\"train.SRC\"]\n",
    "    true_top = entry[\"train.TOP\"]\n",
    "\n",
    "    # Tokenize and preprocess the input text\n",
    "    tokens = tokenize_input(src_text)\n",
    "    # Convert tokens to integers\n",
    "    tokens = tokens_to_ints(tokens, vocab)\n",
    "    # Convert to tensor\n",
    "    tokens = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "\n",
    "    # Get predictions from the first model\n",
    "    model_1_output = model_1(tokens)\n",
    "    first_model_labels = model_1_output.argmax(dim=-1).squeeze(0).tolist()  # Ensure list of labels\n",
    "\n",
    "    # Get predictions from the second model\n",
    "    model_2_output = model_2(tokens)\n",
    "    second_model_labels = model_2_output.argmax(dim=-1).squeeze(0).tolist()  # Ensure list of labels\n",
    "\n",
    "    # Generate TOP_DECOUPLED output\n",
    "    top_decoupled = generate_top_decoupled(src_text, first_model_labels, second_model_labels)\n",
    "\n",
    "    # Preprocess TOP to JSON format\n",
    "    predicted_json = preprocess_top(top_decoupled)\n",
    "    true_json = preprocess_true_top(true_top)\n",
    "    \n",
    "    with open(\"predicted_true.json\", \"a\") as f:\n",
    "        f.write(f\"tokens: {tokens}\\n\")\n",
    "        f.write(f\"true: {true_top}\\n\")\n",
    "    write_comparison_file(predicted_json, true_json, top_decoupled)\n",
    "\n",
    "    # Compare the predicted JSON with the ground truth JSON\n",
    "    return predicted_json == true_json\n",
    "\n",
    "def generate_top_decoupled(text, first_labels, second_labels):\n",
    "    words = text.split()\n",
    "    first_labels = first_labels[:len(words)]\n",
    "    second_labels = second_labels[:len(words)]\n",
    "    \n",
    "    # Debugging output\n",
    "    with open(\"predicted_true.json\", \"a\") as f:\n",
    "        f.write(str(words) + \"\\n\")\n",
    "        f.write(str([next(k for k, v in MODEL_1_LABEL_MAP.items() if v == l) for l in first_labels]) + \"\\n\")\n",
    "        f.write(str([next(k for k, v in MODEL_2_LABEL_MAP.items() if v == l) for l in second_labels]) + \"\\n\\n\") \n",
    "    \n",
    "    \n",
    "    result = [\"(ORDER\"]\n",
    "    current_order_type = None\n",
    "    current_group = None\n",
    "    open_groups = []  # To keep track of open groups for proper closing\n",
    "\n",
    "    for i, (word, first_label, second_label) in enumerate(zip(words, first_labels, second_labels)):\n",
    "        first_label_key = next(\n",
    "            (key for key, value in MODEL_1_LABEL_MAP.items() if value == first_label), None\n",
    "        )\n",
    "        # Handle the first labels (ORDER type: PIZZAORDER, DRINKORDER)\n",
    "        if first_label in [MODEL_1_LABEL_MAP[\"B-PIZZAORDER\"], MODEL_1_LABEL_MAP[\"B-DRINKORDER\"]]:\n",
    "            if current_order_type is not None:\n",
    "                result.append(\")\")  # Close the previous order\n",
    "                open_groups.pop()  # Remove from open_groups stack\n",
    "            current_order_type = \"PIZZAORDER\" if first_label == MODEL_1_LABEL_MAP[\"B-PIZZAORDER\"] else \"DRINKORDER\"\n",
    "            result.append(f\"({current_order_type}\")\n",
    "            open_groups.append(current_order_type)\n",
    "            \n",
    "        # if the first label is I- and the current order type is None, consider it as B- and add the order type\n",
    "        # and do the same if it's an I- but for a different order type\n",
    "        elif first_label_key.startswith(\"I-\") and (current_order_type is None or current_order_type != first_label_key[2:]):\n",
    "            if current_order_type is not None:\n",
    "                result.append(\")\")  # Close the previous order\n",
    "                open_groups.pop()\n",
    "            current_order_type = \"PIZZAORDER\" if first_label == MODEL_1_LABEL_MAP[\"I-PIZZAORDER\"] else \"DRINKORDER\"\n",
    "            result.append(f\"({current_order_type}\")\n",
    "            open_groups.append(current_order_type)\n",
    "            \n",
    "\n",
    "        elif first_label == MODEL_1_LABEL_MAP[\"O\"] and current_order_type is not None:\n",
    "            result.append(\")\")  # Close the current order\n",
    "            open_groups.pop()\n",
    "            current_order_type = None\n",
    "            \n",
    "        elif first_label == MODEL_1_LABEL_MAP[\"O\"] and current_order_type is None:\n",
    "            continue  # Skip the word if it's not part of an order\n",
    "\n",
    "        # Handle the second labels (attributes like NUMBER, SIZE, TOPPING, etc.)\n",
    "        if second_label != MODEL_2_LABEL_MAP[\"O\"]:\n",
    "            second_label_key = next(\n",
    "                (key for key, value in MODEL_2_LABEL_MAP.items() if value == second_label), None\n",
    "            )\n",
    "            if not second_label_key:\n",
    "                print(f\"Warning: Unexpected label {second_label} encountered for word '{word}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            label_type = second_label_key.split(\"-\")[-1]\n",
    "            if label_type not in [\"NEG_TOPPING\", \"NEG_STYLE\"]:\n",
    "                if second_label_key.startswith(\"B-\"):\n",
    "                    # Close the previous group if there is one\n",
    "                    if current_group:\n",
    "                        result.append(\")\")  # Close the previous group\n",
    "                        # since this is positive, if the current top group is a not group close it as well\n",
    "                        if current_group[\"type\"] == \"NEG_TOPPING\" or current_group[\"type\"] == \"NEG_STYLE\":\n",
    "                            result.append(\")\")\n",
    "                            open_groups.pop()\n",
    "                        open_groups.pop()\n",
    "                    current_group = {\"type\": label_type, \"content\": [word]}\n",
    "                    result.append(f\"({label_type} {word}\")\n",
    "                    open_groups.append(label_type)\n",
    "\n",
    "                elif second_label_key.startswith(\"I-\") and current_group and current_group[\"type\"] == label_type:\n",
    "                    current_group[\"content\"].append(word)\n",
    "                    result[-1] += f\" {word}\"  # Append to the last open group\n",
    "\n",
    "                elif second_label_key.startswith(\"I-\") and (not current_group or current_group[\"type\"] != label_type):\n",
    "                    print(f\"Warning: I- tag '{label_type}' for word '{word}' without preceding B- tag. Converting to B-.\")\n",
    "                    # Close the previous group if there is one\n",
    "                    if current_group:\n",
    "                        result.append(\")\")  # Close the previous group\n",
    "                        # since this is positive, if the current top group is a not group close it as well\n",
    "                        if current_group[\"type\"] == \"NEG_TOPPING\" or current_group[\"type\"] == \"NEG_STYLE\":\n",
    "                            result.append(\")\")\n",
    "                            open_groups.pop()\n",
    "                        open_groups.pop()\n",
    "                    current_group = {\"type\": label_type, \"content\": [word]}\n",
    "                    result.append(f\"({label_type} {word}\")\n",
    "                    open_groups.append(label_type)\n",
    "\n",
    "            # Special handling for NEG_TOPPING and NEG_STYLE\n",
    "            else:\n",
    "                if second_label_key.startswith(\"B-\"):\n",
    "                    if current_group:\n",
    "                        result.append(\")\")\n",
    "                        open_groups.pop()\n",
    "                    result.append(f\"(NOT ({'TOPPING' if label_type == 'NEG_TOPPING' else 'STYLE'} {word}\")\n",
    "                    current_group = {\"type\": label_type, \"content\": [word]}\n",
    "                    open_groups.append(label_type)\n",
    "                    open_groups.append(\"NOT\")\n",
    "                elif second_label_key.startswith(\"I-\") and current_group and current_group[\"type\"] == label_type:\n",
    "                    current_group[\"content\"].append(word)\n",
    "                    result[-1] += f\" {word}\"  # Append to the last open group\n",
    "                elif second_label_key.startswith(\"I-\") and (not current_group or current_group[\"type\"] != label_type):\n",
    "                     # Close the previous group if there is one\n",
    "                    if current_group:\n",
    "                        result.append(\")\")\n",
    "                        open_groups.pop()\n",
    "                    print(f\"Warning: I- tag '{label_type}' for word '{word}' without preceding B- tag. Converting to B-.\")\n",
    "                    result.append(f\"(NOT ({'TOPPING' if label_type == 'NEG_TOPPING' else 'STYLE'} {word}\")\n",
    "                    current_group = {\"type\": label_type, \"content\": [word]}\n",
    "                    open_groups.append(\"NOT\")\n",
    "                    open_groups.append(label_type)\n",
    "        # Handle O labels\n",
    "        else:\n",
    "            if current_group:\n",
    "                result.append(\")\")  # Close the current group\n",
    "                open_groups.pop()\n",
    "            current_group = None\n",
    "\n",
    "    # Close any remaining open groups\n",
    "    while open_groups:\n",
    "        result.append(\")\")\n",
    "        open_groups.pop()\n",
    "\n",
    "    result.append(\")\")  # Close the overall ORDER group\n",
    "    return \" \".join(result)\n",
    "\n",
    "# Updated JSON comparison file formatting\n",
    "def write_comparison_file(predicted_json, true_json, top_decoupled):\n",
    "    with open(\"predicted_true.json\", \"a\") as f:\n",
    "        # write top decoupled \n",
    "        f.write(f\"TOP_DECOUPLED: {top_decoupled}\\n\\n\")\n",
    "        # Format both JSONs side by side in a neat way\n",
    "        predicted_str = json.dumps(predicted_json, indent=2)\n",
    "        true_str = json.dumps(true_json, indent=2)\n",
    "\n",
    "        max_width = max(len(line) for line in predicted_str.splitlines()) + 5\n",
    "        max_lines = max(len(predicted_str.splitlines()), len(true_str.splitlines()))\n",
    "        \n",
    "        predicted_lines = predicted_str.splitlines()\n",
    "        true_lines = true_str.splitlines()\n",
    "\n",
    "        f.write(f\"{'-' * (max_width * 2)}\\n\")\n",
    "        f.write(f\"{'Predicted'.center(max_width)}{'True'.center(max_width)}\\n\")\n",
    "        f.write(f\"{'-' * (max_width * 2)}\\n\")\n",
    "        \n",
    "        for i in range(max_lines):\n",
    "            left = predicted_lines[i] if i < len(predicted_lines) else \"\"\n",
    "            right = true_lines[i] if i < len(true_lines) else \"\"\n",
    "            f.write(f\"{left:<{max_width}}{right:<{max_width}}\\n\")\n",
    "        \n",
    "        f.write(f\"{'-' * (max_width * 2)}\\n\")\n",
    "        f.write(f\"Match: {predicted_json == true_json}\\n\")\n",
    "        f.write(f\"{'-' * (max_width * 2)}\\n\\n\")\n",
    "\n",
    "# Main function to process the dataset\n",
    "def process_dataset(input_file):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Clear the debug file\n",
    "    open(\"predicted_true.json\", \"w\").close()\n",
    "\n",
    "    with open(input_file, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            entry = json.loads(line)\n",
    "            if process_entry(entry):\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "    accuracy = correct / total * 100 if total > 0 else 0\n",
    "    print(f\"Accuracy: {accuracy:.2f}% ({correct}/{total})\")\n",
    "    return accuracy\n",
    "\n",
    "process_dataset(\"../dataset2/test_train.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
