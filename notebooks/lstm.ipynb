{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10000 records so far...\n",
      "Processed 20000 records so far...\n",
      "Processed 30000 records so far...\n",
      "Processed 40000 records so far...\n",
      "Processed 50000 records so far...\n",
      "Processed 60000 records so far...\n",
      "Processed 70000 records so far...\n",
      "Processed 80000 records so far...\n",
      "Processed 90000 records so far...\n",
      "Processed 100000 records so far...\n",
      "Processed 110000 records so far...\n",
      "Processed 120000 records so far...\n",
      "Processed 130000 records so far...\n",
      "Processed 140000 records so far...\n",
      "Processed 150000 records so far...\n",
      "Processed 160000 records so far...\n",
      "Processed 170000 records so far...\n",
      "Processed 180000 records so far...\n",
      "Processed 190000 records so far...\n",
      "Processed 200000 records so far...\n",
      "Processed 210000 records so far...\n",
      "Processed 220000 records so far...\n",
      "Processed 230000 records so far...\n",
      "Processed 240000 records so far...\n",
      "Processed 250000 records so far...\n",
      "Processed 260000 records so far...\n",
      "Processed 270000 records so far...\n",
      "Processed 280000 records so far...\n",
      "Processed 290000 records so far...\n",
      "Processed 300000 records so far...\n",
      "Processed 310000 records so far...\n",
      "Processed 320000 records so far...\n",
      "Processed 330000 records so far...\n",
      "Processed 340000 records so far...\n",
      "Processed 350000 records so far...\n",
      "Processed 360000 records so far...\n",
      "Processed 370000 records so far...\n",
      "Processed 380000 records so far...\n",
      "Processed 390000 records so far...\n",
      "Processed 400000 records so far...\n",
      "Processed 410000 records so far...\n",
      "Processed 420000 records so far...\n",
      "Processed 430000 records so far...\n",
      "Processed 440000 records so far...\n",
      "Processed 450000 records so far...\n",
      "Processed 460000 records so far...\n",
      "Processed 470000 records so far...\n",
      "Processed 480000 records so far...\n",
      "Processed 490000 records so far...\n",
      "Processed 500000 records so far...\n",
      "Processed 510000 records so far...\n",
      "Processed 520000 records so far...\n",
      "Processed 530000 records so far...\n",
      "Processed 540000 records so far...\n",
      "Processed 550000 records so far...\n",
      "Processed 560000 records so far...\n",
      "Processed 570000 records so far...\n",
      "Processed 580000 records so far...\n",
      "Processed 590000 records so far...\n",
      "Processed 600000 records so far...\n",
      "Processed 610000 records so far...\n",
      "Processed 620000 records so far...\n",
      "Processed 630000 records so far...\n",
      "Processed 640000 records so far...\n",
      "Processed 650000 records so far...\n",
      "Processed 660000 records so far...\n",
      "Processed 670000 records so far...\n",
      "Processed 680000 records so far...\n",
      "Processed 690000 records so far...\n",
      "Processed 700000 records so far...\n",
      "Processed 710000 records so far...\n",
      "Processed 720000 records so far...\n",
      "Processed 730000 records so far...\n",
      "Processed 740000 records so far...\n",
      "Processed 750000 records so far...\n",
      "Processed 760000 records so far...\n",
      "Processed 770000 records so far...\n",
      "Processed 780000 records so far...\n",
      "Processed 790000 records so far...\n",
      "Processed 800000 records so far...\n",
      "Processed 810000 records so far...\n",
      "Processed 820000 records so far...\n",
      "Processed 830000 records so far...\n",
      "Processed 840000 records so far...\n",
      "Processed 850000 records so far...\n",
      "Processed 860000 records so far...\n",
      "Processed 870000 records so far...\n",
      "Processed 880000 records so far...\n",
      "Processed 890000 records so far...\n",
      "Processed 900000 records so far...\n",
      "Processed 910000 records so far...\n",
      "Processed 920000 records so far...\n",
      "Processed 930000 records so far...\n",
      "Processed 940000 records so far...\n",
      "Processed 950000 records so far...\n",
      "Processed 960000 records so far...\n",
      "Processed 970000 records so far...\n",
      "Processed 980000 records so far...\n",
      "Processed 990000 records so far...\n",
      "Processed 1000000 records so far...\n",
      "Processed 1010000 records so far...\n",
      "Processed 1020000 records so far...\n",
      "Processed 1030000 records so far...\n",
      "Processed 1040000 records so far...\n",
      "Processed 1050000 records so far...\n",
      "Processed 1060000 records so far...\n",
      "Processed 1070000 records so far...\n",
      "Processed 1080000 records so far...\n",
      "Processed 1090000 records so far...\n",
      "Processed 1100000 records so far...\n",
      "Processed 1110000 records so far...\n",
      "Processed 1120000 records so far...\n",
      "Processed 1130000 records so far...\n",
      "Processed 1140000 records so far...\n",
      "Processed 1150000 records so far...\n",
      "Processed 1160000 records so far...\n",
      "Processed 1170000 records so far...\n",
      "Processed 1180000 records so far...\n",
      "Processed 1190000 records so far...\n",
      "Processed 1200000 records so far...\n",
      "Processed 1210000 records so far...\n",
      "Processed 1220000 records so far...\n",
      "Processed 1230000 records so far...\n",
      "Processed 1240000 records so far...\n",
      "Processed 1250000 records so far...\n",
      "Processed 1260000 records so far...\n",
      "Processed 1270000 records so far...\n",
      "Processed 1280000 records so far...\n",
      "Processed 1290000 records so far...\n",
      "Processed 1300000 records so far...\n",
      "Processed 1310000 records so far...\n",
      "Processed 1320000 records so far...\n",
      "Processed 1330000 records so far...\n",
      "Processed 1340000 records so far...\n",
      "Processed 1350000 records so far...\n",
      "Processed 1360000 records so far...\n",
      "Processed 1370000 records so far...\n",
      "Processed 1380000 records so far...\n",
      "Processed 1390000 records so far...\n",
      "Processed 1400000 records so far...\n",
      "Processed 1410000 records so far...\n",
      "Processed 1420000 records so far...\n",
      "Processed 1430000 records so far...\n",
      "Processed 1440000 records so far...\n",
      "Processed 1450000 records so far...\n",
      "Processed 1460000 records so far...\n",
      "Processed 1470000 records so far...\n",
      "Processed 1480000 records so far...\n",
      "Processed 1490000 records so far...\n",
      "Processed 1500000 records so far...\n",
      "Processed 1510000 records so far...\n",
      "Processed 1520000 records so far...\n",
      "Processed 1530000 records so far...\n",
      "Processed 1540000 records so far...\n",
      "Processed 1550000 records so far...\n",
      "Processed 1560000 records so far...\n",
      "Processed 1570000 records so far...\n",
      "Processed 1580000 records so far...\n",
      "Processed 1590000 records so far...\n",
      "Processed 1600000 records so far...\n",
      "Processed 1610000 records so far...\n",
      "Processed 1620000 records so far...\n",
      "Processed 1630000 records so far...\n",
      "Processed 1640000 records so far...\n",
      "Processed 1650000 records so far...\n",
      "Processed 1660000 records so far...\n",
      "Processed 1670000 records so far...\n",
      "Processed 1680000 records so far...\n",
      "Processed 1690000 records so far...\n",
      "Processed 1700000 records so far...\n",
      "Processed 1710000 records so far...\n",
      "Processed 1720000 records so far...\n",
      "Processed 1730000 records so far...\n",
      "Processed 1740000 records so far...\n",
      "Processed 1750000 records so far...\n",
      "Processed 1760000 records so far...\n",
      "Processed 1770000 records so far...\n",
      "Processed 1780000 records so far...\n",
      "Processed 1790000 records so far...\n",
      "Processed 1800000 records so far...\n",
      "Processed 1810000 records so far...\n",
      "Processed 1820000 records so far...\n",
      "Processed 1830000 records so far...\n",
      "Processed 1840000 records so far...\n",
      "Processed 1850000 records so far...\n",
      "Processed 1860000 records so far...\n",
      "Processed 1870000 records so far...\n",
      "Processed 1880000 records so far...\n",
      "Processed 1890000 records so far...\n",
      "Processed 1900000 records so far...\n",
      "Processed 1910000 records so far...\n",
      "Processed 1920000 records so far...\n",
      "Processed 1930000 records so far...\n",
      "Processed 1940000 records so far...\n",
      "Processed 1950000 records so far...\n",
      "Processed 1960000 records so far...\n",
      "Processed 1970000 records so far...\n",
      "Processed 1980000 records so far...\n",
      "Processed 1990000 records so far...\n",
      "Processed 2000000 records so far...\n",
      "Processed 2010000 records so far...\n",
      "Processed 2020000 records so far...\n",
      "Processed 2030000 records so far...\n",
      "Processed 2040000 records so far...\n",
      "Processed 2050000 records so far...\n",
      "Processed 2060000 records so far...\n",
      "Processed 2070000 records so far...\n",
      "Processed 2080000 records so far...\n",
      "Processed 2090000 records so far...\n",
      "Processed 2100000 records so far...\n",
      "Processed 2110000 records so far...\n",
      "Processed 2120000 records so far...\n",
      "Processed 2130000 records so far...\n",
      "Processed 2140000 records so far...\n",
      "Processed 2150000 records so far...\n",
      "Processed 2160000 records so far...\n",
      "Processed 2170000 records so far...\n",
      "Processed 2180000 records so far...\n",
      "Processed 2190000 records so far...\n",
      "Processed 2200000 records so far...\n",
      "Processed 2210000 records so far...\n",
      "Processed 2220000 records so far...\n",
      "Processed 2230000 records so far...\n",
      "Processed 2240000 records so far...\n",
      "Processed 2250000 records so far...\n",
      "Processed 2260000 records so far...\n",
      "Processed 2270000 records so far...\n",
      "Processed 2280000 records so far...\n",
      "Processed 2290000 records so far...\n",
      "Processed 2300000 records so far...\n",
      "Processed 2310000 records so far...\n",
      "Processed 2320000 records so far...\n",
      "Processed 2330000 records so far...\n",
      "Processed 2340000 records so far...\n",
      "Processed 2350000 records so far...\n",
      "Processed 2360000 records so far...\n",
      "Processed 2370000 records so far...\n",
      "Processed 2380000 records so far...\n",
      "Processed 2390000 records so far...\n",
      "Processed 2400000 records so far...\n",
      "Processed 2410000 records so far...\n",
      "Processed 2420000 records so far...\n",
      "Processed 2430000 records so far...\n",
      "Processed 2440000 records so far...\n",
      "Processed 2450000 records so far...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "sys.path.append(\"..\")\n",
    "from utils.data_preprocessing import preprocess_text\n",
    "from utils.feature_extraction import bag_of_words, tfidf_features, extract_embeddings\n",
    "\n",
    "train_path = '../dataset/PIZZA_train.json'\n",
    "test_path = '../dataset/PIZZA_dev.json'\n",
    "def read_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            try:\n",
    "                record = json.loads(line.strip())\n",
    "                data.append(record)\n",
    "                \n",
    "                # Process in chunks of 10,000 records\n",
    "                if i > 0 and i % 10000 == 0:\n",
    "                    print(f\"Processed {i} records so far...\")\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return data\n",
    "\n",
    "# Convert remaining data to DataFrame\n",
    "data = read_data(train_path)\n",
    "if data:\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "data = read_data(test_path)\n",
    "if data:\n",
    "    dev = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = df['train.SRC']\n",
    "output_texts = df['train.TOP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "input_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "output_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "output_tokenizer.fit_on_texts(output_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Text to Sequences\n",
    "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
    "output_sequences = output_tokenizer.texts_to_sequences(output_texts)\n",
    "\n",
    "# Add Padding\n",
    "max_input_len = max(len(seq) for seq in input_sequences)\n",
    "max_output_len = max(len(seq) for seq in output_sequences)\n",
    "\n",
    "input_sequences = tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_input_len, padding=\"post\")\n",
    "output_sequences = tf.keras.preprocessing.sequence.pad_sequences(output_sequences, maxlen=max_output_len, padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "output_vocab_size = len(output_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "START_TOKEN = output_tokenizer.word_index['<start>'] if '<start>' in output_tokenizer.word_index else 0\n",
    "def data_generator(input_sequences, output_sequences, batch_size):\n",
    "    num_samples = len(input_sequences)\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_input = input_sequences[i:i + batch_size]\n",
    "\n",
    "        # Prepare decoder inputs\n",
    "        batch_decoder_input = np.zeros((len(batch_input), max_output_len), dtype=np.int32)\n",
    "        for j, seq in enumerate(output_sequences[i:i + batch_size]):\n",
    "            shifted_seq = [START_TOKEN] + seq[:-1].tolist()\n",
    "            batch_decoder_input[j, :len(shifted_seq)] = shifted_seq\n",
    "\n",
    "        # Prepare target outputs (padded to match max_output_len)\n",
    "        batch_output = np.zeros((len(batch_input), max_output_len), dtype=np.int32)\n",
    "        for j, seq in enumerate(output_sequences[i:i + batch_size]):\n",
    "            batch_output[j, :len(seq)] = seq\n",
    "\n",
    "        yield ([batch_input, batch_decoder_input], batch_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = tf.convert_to_tensor(input_sequences, dtype=tf.int32)\n",
    "output_sequences = tf.convert_to_tensor(output_sequences, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(input_sequences, output_sequences, batch_size),\n",
    "    output_signature=(\n",
    "        (  # Encoder and decoder inputs\n",
    "            tf.TensorSpec(shape=(None, max_input_len), dtype=tf.int32),\n",
    "            tf.TensorSpec(shape=(None, max_output_len), dtype=tf.int32),\n",
    "        ),\n",
    "        tf.TensorSpec(shape=(None, max_output_len - 1), dtype=tf.int32),  # Target outputs\n",
    "    )\n",
    ").shuffle(buffer_size=1024).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "lstm_units = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tf.keras.Input(shape=(max_input_len,))\n",
    "encoder_embedding = tf.keras.layers.Embedding(input_vocab_size, embedding_dim)(encoder_inputs)\n",
    "encoder_lstm = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(lstm_units, return_sequences=False, return_state=True)\n",
    ")\n",
    "_, forward_h, forward_c, backward_h, backward_c = encoder_lstm(encoder_embedding)\n",
    "encoder_state_h = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
    "encoder_state_c = tf.keras.layers.Concatenate()([forward_c, backward_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = tf.keras.Input(shape=(max_output_len,))\n",
    "decoder_embedding = tf.keras.layers.Embedding(output_vocab_size, embedding_dim)(decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM(2 * lstm_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[encoder_state_h, encoder_state_c])\n",
    "decoder_dense = tf.keras.layers.Dense(output_vocab_size, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_23\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_23\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_19      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_19        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">38,272</span> │ input_layer_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_20      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_7     │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">788,480</span> │ embedding_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_20        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">39,424</span> │ input_layer_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ bidirectional_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ bidirectional_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │ embedding_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │ concatenate_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │ concatenate_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">308</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">158,004</span> │ lstm_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_19      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_19        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m38,272\u001b[0m │ input_layer_19[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_20      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional_7     │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),     │    \u001b[38;5;34m788,480\u001b[0m │ embedding_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_20        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m39,424\u001b[0m │ input_layer_20[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional_7[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ bidirectional_7[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional_7[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ bidirectional_7[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_20 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m1,312,768\u001b[0m │ embedding_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │ concatenate_14[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │ concatenate_15[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m308\u001b[0m)   │    \u001b[38;5;34m158,004\u001b[0m │ lstm_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,336,948</span> (8.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,336,948\u001b[0m (8.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,336,948</span> (8.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,336,948\u001b[0m (8.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} AttributeError: EagerTensor object has no attribute 'tolist'. \n        If you are looking for numpy-related methods, please run the following:\n        tf.experimental.numpy.experimental_enable_numpy_behavior()\n      \nTraceback (most recent call last):\n\n  File \"C:\\Users\\Hima\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"C:\\Users\\Hima\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\Hima\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\Hima\\AppData\\Local\\Temp\\ipykernel_4180\\1276729944.py\", line 11, in data_generator\n    shifted_seq = [START_TOKEN] + seq[:-1].tolist()\n                                  ^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\Hima\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\framework\\tensor.py\", line 255, in __getattr__\n    raise AttributeError(\n\nAttributeError: EagerTensor object has no attribute 'tolist'. \n        If you are looking for numpy-related methods, please run the following:\n        tf.experimental.numpy.experimental_enable_numpy_behavior()\n      \n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      2\u001b[0m     encoder_input, decoder_input \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m     target_output \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:826\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    825\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_internal()\n\u001b[0;32m    827\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:776\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 776\u001b[0m   ret \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39miterator_get_next(\n\u001b[0;32m    777\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource,\n\u001b[0;32m    778\u001b[0m       output_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types,\n\u001b[0;32m    779\u001b[0m       output_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_shapes)\n\u001b[0;32m    781\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3113\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3111\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3113\u001b[0m   _ops\u001b[38;5;241m.\u001b[39mraise_from_not_ok_status(e, name)\n\u001b[0;32m   3114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   3115\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\framework\\ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mUnknownError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} AttributeError: EagerTensor object has no attribute 'tolist'. \n        If you are looking for numpy-related methods, please run the following:\n        tf.experimental.numpy.experimental_enable_numpy_behavior()\n      \nTraceback (most recent call last):\n\n  File \"C:\\Users\\Hima\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"C:\\Users\\Hima\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\Hima\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\Hima\\AppData\\Local\\Temp\\ipykernel_4180\\1276729944.py\", line 11, in data_generator\n    shifted_seq = [START_TOKEN] + seq[:-1].tolist()\n                                  ^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\Hima\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\framework\\tensor.py\", line 255, in __getattr__\n    raise AttributeError(\n\nAttributeError: EagerTensor object has no attribute 'tolist'. \n        If you are looking for numpy-related methods, please run the following:\n        tf.experimental.numpy.experimental_enable_numpy_behavior()\n      \n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "for batch in dataset.take(1):\n",
    "    encoder_input, decoder_input = batch[0]\n",
    "    target_output = batch[1]\n",
    "    print(\"Encoder Input Shape:\", encoder_input.shape)\n",
    "    print(\"Decoder Input Shape:\", decoder_input.shape)\n",
    "    print(\"Target Output Shape:\", target_output.shape)\n",
    "\n",
    "    # Forward pass test\n",
    "    model([encoder_input, decoder_input])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same shape up until the last dimension: target.shape=(None, 41), output.shape=(None, 42, 308)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      2\u001b[0m     dataset, \n\u001b[0;32m      3\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:626\u001b[0m, in \u001b[0;36msparse_categorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n\u001b[1;32m--> 626\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    627\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    628\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mup until the last dimension: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    629\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    630\u001b[0m         )\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m from_logits:\n\u001b[0;32m    633\u001b[0m     output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mclip_by_value(\n\u001b[0;32m    634\u001b[0m         output, backend\u001b[38;5;241m.\u001b[39mepsilon(), \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m backend\u001b[38;5;241m.\u001b[39mepsilon()\n\u001b[0;32m    635\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Arguments `target` and `output` must have the same shape up until the last dimension: target.shape=(None, 41), output.shape=(None, 42, 308)"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    dataset, \n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../weights/seq2seq_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
