{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"ORDER\": {\n",
      "    \"PIZZAORDER\": [\n",
      "      {\n",
      "        \"NUMBER\": \"one\",\n",
      "        \"SIZE\": \"large\",\n",
      "        \"STYLE\": \"thin crust\",\n",
      "        \"AllTopping\": [\n",
      "          {\n",
      "            \"NOT\": false,\n",
      "            \"Quantity\": null,\n",
      "            \"Topping\": \"hot cheese\"\n",
      "          },\n",
      "          {\n",
      "            \"NOT\": false,\n",
      "            \"Quantity\": null,\n",
      "            \"Topping\": \"pepperoni\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"NUMBER\": \"two\",\n",
      "        \"SIZE\": \"medium\",\n",
      "        \"STYLE\": \"deep dish\",\n",
      "        \"AllTopping\": [\n",
      "          {\n",
      "            \"NOT\": true,\n",
      "            \"Quantity\": null,\n",
      "            \"Topping\": \"mushrooms\"\n",
      "          },\n",
      "          {\n",
      "            \"NOT\": true,\n",
      "            \"Quantity\": \"extra\",\n",
      "            \"Topping\": \"olives\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"DRINKORDER\": [\n",
      "      {\n",
      "        \"NUMBER\": \"five\",\n",
      "        \"SIZE\": \"one liter\",\n",
      "        \"DRINKTYPE\": \"lemon ice tea\",\n",
      "        \"CONTAINERTYPE\": \"bottles\"\n",
      "      },\n",
      "      {\n",
      "        \"NUMBER\": \"three\",\n",
      "        \"SIZE\": \"two liters\",\n",
      "        \"DRINKTYPE\": \"cola\",\n",
      "        \"CONTAINERTYPE\": \"cans\"\n",
      "      },\n",
      "      {\n",
      "        \"NUMBER\": \"three\",\n",
      "        \"SIZE\": \"two liters\",\n",
      "        \"DRINKTYPE\": \"cola\",\n",
      "        \"CONTAINERTYPE\": \"cans\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def tokenize(s):\n",
    "    # Extract tokens: parentheses or sequences of non-whitespace, non-parenthesis characters.\n",
    "    tokens = re.findall(r'\\(|\\)|[^\\s()]+', s)\n",
    "    return tokens\n",
    "\n",
    "def tokens_to_ints(tokens, vocab):\n",
    "    # map the tokens to integers from vocab\n",
    "    # if the token is not in the vocab, use the index of the unknown token\n",
    "    return [vocab.get(token, vocab['<UNK>']) for token in tokens]\n",
    "\n",
    "def parse_tokens(tokens):\n",
    "    # Parse tokens into a nested list structure\n",
    "    stack = []\n",
    "    current_list = []\n",
    "    for token in tokens:\n",
    "        if token == '(':\n",
    "            stack.append(current_list)\n",
    "            current_list = []\n",
    "        elif token == ')':\n",
    "            finished = current_list\n",
    "            current_list = stack.pop()\n",
    "            current_list.append(finished)\n",
    "        else:\n",
    "            current_list.append(token)\n",
    "    return current_list\n",
    "\n",
    "def normalize_structure(tree):\n",
    "    if not isinstance(tree, list):\n",
    "        return None\n",
    "\n",
    "    def is_key(token):\n",
    "        return token in [\n",
    "            \"ORDER\", \"PIZZAORDER\", \"DRINKORDER\", \"NUMBER\", \"SIZE\", \"STYLE\", \"TOPPING\",\n",
    "            \"COMPLEX_TOPPING\", \"QUANTITY\", \"VOLUME\", \"DRINKTYPE\", \"CONTAINERTYPE\", \"NOT\"\n",
    "        ]\n",
    "\n",
    "    # Clean the list by keeping sublists and tokens as-is for further analysis\n",
    "    cleaned = []\n",
    "    for el in tree:\n",
    "        cleaned.append(el)\n",
    "\n",
    "    if len(cleaned) > 0 and isinstance(cleaned[0], str) and is_key(cleaned[0]):\n",
    "        key = cleaned[0]\n",
    "        if key == \"ORDER\":\n",
    "            pizzaorders = []\n",
    "            drinkorders = []\n",
    "            for sub in cleaned[1:]:\n",
    "                node = normalize_structure(sub)\n",
    "                if isinstance(node, dict):\n",
    "                    if \"PIZZAORDER\" in node:\n",
    "                        if isinstance(node[\"PIZZAORDER\"], list):\n",
    "                            pizzaorders.extend(node[\"PIZZAORDER\"])\n",
    "                        else:\n",
    "                            pizzaorders.append(node[\"PIZZAORDER\"])\n",
    "                    if \"DRINKORDER\" in node:\n",
    "                        if isinstance(node[\"DRINKORDER\"], list):\n",
    "                            drinkorders.extend(node[\"DRINKORDER\"])\n",
    "                        else:\n",
    "                            drinkorders.append(node[\"DRINKORDER\"])\n",
    "                    if node.get(\"TYPE\") == \"PIZZAORDER\":\n",
    "                        pizzaorders.append(node)\n",
    "                    if node.get(\"TYPE\") == \"DRINKORDER\":\n",
    "                        drinkorders.append(node)\n",
    "            result = {}\n",
    "            if pizzaorders:\n",
    "                result[\"PIZZAORDER\"] = pizzaorders\n",
    "            if drinkorders:\n",
    "                result[\"DRINKORDER\"] = drinkorders\n",
    "            if result:\n",
    "                return {\"ORDER\": result}\n",
    "            else:\n",
    "                return {}\n",
    "\n",
    "        elif key == \"PIZZAORDER\":\n",
    "            number = None\n",
    "            size = None\n",
    "            style = None\n",
    "            toppings = []\n",
    "            for sub in cleaned[1:]:\n",
    "                node = normalize_structure(sub)\n",
    "                if isinstance(node, dict):\n",
    "                    t = node.get(\"TYPE\")\n",
    "                    if t == \"NUMBER\":\n",
    "                        number = node[\"VALUE\"]\n",
    "                    elif t == \"SIZE\":\n",
    "                        size = node[\"VALUE\"]\n",
    "                    elif t == \"STYLE\":\n",
    "                        style = node[\"VALUE\"]\n",
    "                    elif t == \"TOPPING\":\n",
    "                        toppings.append(node)\n",
    "            result = {}\n",
    "            if number is not None:\n",
    "                result[\"NUMBER\"] = number\n",
    "            if size is not None:\n",
    "                result[\"SIZE\"] = size\n",
    "            if style is not None:\n",
    "                result[\"STYLE\"] = style\n",
    "            if toppings:\n",
    "                result[\"AllTopping\"] = toppings\n",
    "            # Mark type internally, will remove later\n",
    "            result[\"TYPE\"] = \"PIZZAORDER\"\n",
    "            return result\n",
    "\n",
    "        elif key == \"DRINKORDER\":\n",
    "            number = None\n",
    "            volume = None\n",
    "            drinktype = None\n",
    "            containertype = None\n",
    "            for sub in cleaned[1:]:\n",
    "                node = normalize_structure(sub)\n",
    "                if isinstance(node, dict):\n",
    "                    t = node.get(\"TYPE\")\n",
    "                    if t == \"NUMBER\":\n",
    "                        number = node[\"VALUE\"]\n",
    "                    elif t == \"VOLUME\" or t == \"SIZE\":\n",
    "                        volume = node[\"VALUE\"]\n",
    "                    elif t == \"DRINKTYPE\":\n",
    "                        drinktype = node[\"VALUE\"]\n",
    "                    elif t == \"CONTAINERTYPE\":\n",
    "                        containertype = node[\"VALUE\"]\n",
    "            result = {}\n",
    "            if number is not None:\n",
    "                result[\"NUMBER\"] = number\n",
    "            if volume is not None:\n",
    "                result[\"SIZE\"] = volume\n",
    "            if drinktype is not None:\n",
    "                result[\"DRINKTYPE\"] = drinktype\n",
    "            if containertype is not None:\n",
    "                result[\"CONTAINERTYPE\"] = containertype\n",
    "            result[\"TYPE\"] = \"DRINKORDER\"\n",
    "            return result\n",
    "\n",
    "        elif key in [\"NUMBER\",\"SIZE\",\"STYLE\",\"VOLUME\",\"DRINKTYPE\",\"CONTAINERTYPE\",\"QUANTITY\"]:\n",
    "            values = []\n",
    "            for el in cleaned[1:]:\n",
    "                if isinstance(el, str):\n",
    "                    values.append(el)\n",
    "            value_str = \" \".join(values).strip()\n",
    "            return {\n",
    "                \"TYPE\": key,\n",
    "                \"VALUE\": value_str\n",
    "            }\n",
    "\n",
    "        elif key == \"TOPPING\":\n",
    "            values = []\n",
    "            for el in cleaned[1:]:\n",
    "                if isinstance(el, str):\n",
    "                    values.append(el)\n",
    "            topping_str = \" \".join(values).strip()\n",
    "            return {\n",
    "                \"TYPE\": \"TOPPING\",\n",
    "                \"NOT\": False,\n",
    "                \"Quantity\": None,\n",
    "                \"Topping\": topping_str\n",
    "            }\n",
    "            \n",
    "        elif key == \"QUANTITY\":\n",
    "            # look for the first TOPPING key after you and assign the quantity to it\n",
    "            quantity = None\n",
    "            topping = None\n",
    "            for sub in cleaned[1:]:\n",
    "                node = normalize_structure(sub)\n",
    "                if isinstance(node, dict):\n",
    "                    t = node.get(\"TYPE\")\n",
    "                    if t == \"QUANTITY\":\n",
    "                        quantity = node[\"VALUE\"]\n",
    "                    elif t == \"TOPPING\":\n",
    "                        topping = node[\"Topping\"]\n",
    "\n",
    "        elif key == \"COMPLEX_TOPPING\":\n",
    "            quantity = None\n",
    "            topping = None\n",
    "            for sub in cleaned[1:]:\n",
    "                node = normalize_structure(sub)\n",
    "                if isinstance(node, dict):\n",
    "                    t = node.get(\"TYPE\")\n",
    "                    if t == \"QUANTITY\":\n",
    "                        quantity = node[\"VALUE\"]\n",
    "                    elif t == \"TOPPING\":\n",
    "                        topping = node[\"Topping\"]\n",
    "            return {\n",
    "                \"TYPE\": \"TOPPING\",\n",
    "                \"NOT\": False,\n",
    "                \"Quantity\": quantity,\n",
    "                \"Topping\": topping\n",
    "            }\n",
    "\n",
    "        elif key == \"NOT\":\n",
    "            for sub in cleaned[1:]:\n",
    "                node = normalize_structure(sub)\n",
    "                if isinstance(node, dict) and node.get(\"TYPE\") == \"TOPPING\":\n",
    "                    node[\"NOT\"] = True\n",
    "                    if \"Quantity\" not in node:\n",
    "                        node[\"Quantity\"] = None\n",
    "                    return node\n",
    "            return None\n",
    "\n",
    "    else:\n",
    "        # Try to parse sublists and combine orders found\n",
    "        combined_order = {\"PIZZAORDER\": [], \"DRINKORDER\": []}\n",
    "        found_order = False\n",
    "\n",
    "        for el in cleaned:\n",
    "            node = normalize_structure(el)\n",
    "            if isinstance(node, dict):\n",
    "                if \"ORDER\" in node:\n",
    "                    found_order = True\n",
    "                    order_node = node[\"ORDER\"]\n",
    "                    if \"PIZZAORDER\" in order_node:\n",
    "                        combined_order[\"PIZZAORDER\"].extend(order_node[\"PIZZAORDER\"])\n",
    "                    if \"DRINKORDER\" in order_node:\n",
    "                        combined_order[\"DRINKORDER\"].extend(order_node[\"DRINKORDER\"])\n",
    "                elif node.get(\"TYPE\") == \"PIZZAORDER\":\n",
    "                    found_order = True\n",
    "                    combined_order[\"PIZZAORDER\"].append(node)\n",
    "                elif node.get(\"TYPE\") == \"DRINKORDER\":\n",
    "                    found_order = True\n",
    "                    combined_order[\"DRINKORDER\"].append(node)\n",
    "\n",
    "        if found_order:\n",
    "            final = {}\n",
    "            if combined_order[\"PIZZAORDER\"]:\n",
    "                final[\"PIZZAORDER\"] = combined_order[\"PIZZAORDER\"]\n",
    "            if combined_order[\"DRINKORDER\"]:\n",
    "                final[\"DRINKORDER\"] = combined_order[\"DRINKORDER\"]\n",
    "            return {\"ORDER\": final} if final else {}\n",
    "\n",
    "        return None\n",
    "\n",
    "def remove_type_keys(obj):\n",
    "    # Recursively remove \"TYPE\" keys from all dictionaries\n",
    "    if isinstance(obj, dict):\n",
    "        obj.pop(\"TYPE\", None)\n",
    "        for k, v in obj.items():\n",
    "            remove_type_keys(v)\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            remove_type_keys(item)\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = tokenize(text)\n",
    "    parsed = parse_tokens(tokens)\n",
    "    result = normalize_structure(parsed)\n",
    "    remove_type_keys(result)\n",
    "    return result\n",
    "\n",
    "input_str = \"(ORDER potato potato junior (PIZZAORDER (NUMBER one) (SIZE large) (STYLE thin crust) (TOPPING hot cheese) (TOPPING pepperoni) ) (PIZZAORDER (NUMBER two) (SIZE medium) (STYLE deep dish) (NOT (TOPPING mushrooms) ) (NOT (COMPLEX_TOPPING (QUANTITY extra) (TOPPING olives) ) ) ) (DRINKORDER (NUMBER five) (VOLUME one liter) (DRINKTYPE lemon ice tea) (CONTAINERTYPE bottles)) (DRINKORDER (NUMBER three) (VOLUME two liters) (DRINKTYPE cola) (CONTAINERTYPE cans)) (DRINKORDER (NUMBER three) (VOLUME two liters) (DRINKTYPE cola) (CONTAINERTYPE cans) ) )\"\n",
    "\n",
    "result = preprocess(input_str)\n",
    "\n",
    "print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'large': 4, 'pie': 5, 'with': 6, 'green': 7, 'pepper': 8, 'and': 9, 'extra': 10, 'ham': 11, 'party': 12, 'size': 13, 'stuffed': 14, 'crust': 15, 'artichokes': 16, 'mushroom': 17, 'i': 18, 'want': 19, 'one': 20, 'regular': 21, 'pizza': 22, 'without': 23, 'any': 24, 'basil': 25, 'a': 26, 'american': 27, 'cheese': 28, 'little': 29, 'bit': 30, 'of': 31, 'sausage': 32, '\"d\"': 33, 'like': 34, 'sized': 35, 'high': 36, 'rise': 37, 'dough': 38, 'lot': 39, 'banana': 40, 'chicken': 41, 'black': 42, 'olives': 43, 'sauce': 44, 'broccoli': 45, 'peperonni': 46, 'italian': 47, 'can': 48, 'have': 49, 'flatbread': 50, 'style': 51, 'lunch': 52, '-': 53, 'blue': 54, 'need': 55, 'caramelized': 56, 'onions': 57, 'combination': 58, 'eggplant': 59, 'pecorino': 60, 'New': 61, 'York': 62, 'artichoke': 63, 'spinach': 64, 'Neapolitan': 65, 'bacon': 66, 'tofu': 67, 'grilled': 68, 'mozzarella': 69, 'vegan': 70, 'pepperoni': 71, 'no': 72, 'feta': 73, 'yellow': 74, 'peppers': 75, 'pickles': 76, 'double': 77, 'provolone': 78, 'sun': 79, '-dried': 80, 'tomatoes': 81, 'hot': 82, 'mushrooms': 83, 'small': 84, 'dried': 85, 'meatlover': 86, 'salami': 87, 'truffle': 88, 'oil': 89, 'artisan': 90, 'gluten': 91, '-free': 92, 'chorizo': 93, 'jalapenos': 94, 'pineapple': 95, 'low': 96, 'fat': 97, 'Sicilian': 98, 'deep': 99, 'dish': 100, 'pestos': 101, 'roasted': 102, 'garlic': 103, 'prosciutto': 104, 'wood': 105, '-fired': 106, 'big': 107, 'meat': 108, 'personal': 109, 'balsamic': 110, 'glaze': 111, 'thick': 112, 'bbq': 113, 'crusts': 114, 'peppperoni': 115, 'new': 116, 'york': 117, 'anchovies': 118, 'every': 119, 'pan': 120, 'just': 121, 'pepperonis': 122, 'meatball': 123, 'yorker': 124, 'tomato': 125, 'balzamic': 126, 'onion': 127, 'medium': 128, 'arugula': 129, 'only': 130, 'red': 131, 'lettuce': 132, 'free': 133, 'crispy': 134, 'thin': 135, 'cracker': 136, '-thin': 137, 'not': 138, 'much': 139, 'pesto': 140, 'margarita': 141, 'ranch': 142, '-stuffed': 143, 'peperoni': 144, 'olive': 145, 'spiced': 146, 'peperronni': 147, 'hawaiian': 148, 'peperroni': 149, 'flakes': 150, 'spicy': 151, 'oregano': 152, 'shrimps': 153, 'cauliflower': 154, 'peppperonis': 155, 'lots': 156, 'pickle': 157, 'kalamata': 158, 'hand': 159, '-tossed': 160, 'Chicago': 161, 'Detroit': 162, 'peperonis': 163, 'all': 164, 'the': 165, 'peas': 166, 'napolitana': 167, 'cheeses': 168, 'white': 169, 'tuna': 170, 'vegetarian': 171, 'rosemary': 172, 'carrots': 173, 'whole': 174, 'wheat': 175, 'everything': 176, 'mediterranean': 177, 'margherita': 178, 'sausages': 179, 'cumin': 180, 'parmesan': 181, 'pineapples': 182, 'shrimp': 183, 'pineaples': 184, 'bay': 185, 'leaves': 186, 'hams': 187, 'tiny': 188, 'parsley': 189, 'flake': 190, 'neapolitan': 191, 'jalapeno': 192, 'meatlovers': 193, 'veggie': 194, 'buffalo': 195, 'veggies': 196, 'deepdish': 197, 'many': 198, 'pea': 199, 'fried': 200, 'powder': 201, 'lover': 202, 'pineaple': 203, 'ricotta': 204, 'ground': 205, 'beef': 206, 'supreme': 207, 'lovers': 208, 'topping': 209, 'alfredo': 210, 'oils': 211, 'sourdough': 212, 'works': 213, 'toppings': 214, 'chickens': 215, 'pepperss': 216, 'keto': 217, 'applewood': 218, 'cheddar': 219, 'brocoli': 220, 'cheeseburger': 221, 'apple': 222, 'chicago': 223, 'carrot': 224, 'cherry': 225, 'chorizos': 226, 'pulled': 227, 'pork': 228, 'jalapenoss': 229, 'vegetables': 230, 'anchovy': 231, 'mozarella': 232, 'bacons': 233, 'mexican': 234, 'barbecue': 235, 'tomatoess': 236, 'chorrizo': 237, 'garlics': 238, 'tomatoeses': 239, 'broccolis': 240, 'eggplants': 241, 'bean': 242, 'arugulas': 243, 'beans': 244, 'artichokess': 245, 'onionss': 246, 'anchoviess': 247, 'salamis': 248, 'basiles': 249, 'provolones': 250, 'three': 251, 'pizzas': 252, 'hold': 253, 'four': 254, 'pies': 255, 'avoid': 256, 'hate': 257, 'two': 258, 'five': 259, 'tofus': 260, 'spinachs': 261, 'mushroomss': 262, 'mushroomses': 263, 'arugulaes': 264, 'olivess': 265, 'basils': 266, 'prosciuttos': 267, 'sausagees': 268, 'olivesoni': 269, 'pepperonies': 270, 'onionses': 271, 'oiloni': 272, 'cheeseoni': 273, 'prosciuttoes': 274, 'garlices': 275, 'chorizoes': 276, 'peppersoni': 277, 'broccolies': 278, 'spinaches': 279, 'artichokesoni': 280, 'chickenes': 281, 'arugulaoni': 282, 'tofues': 283, 'onionsoni': 284, 'tofuoni': 285, 'provolonees': 286, 'pepperonioni': 287, 'bacones': 288, 'prosciuttooni': 289, 'provoloneoni': 290, 'jalapenoses': 291, 'cheesees': 292, 'eggplantoni': 293, '-jalapenos': 294, '-green': 295, '-sun-dried': 296, '-eggplantes': 297, 'pineappleoni': 298, '-prosciutto': 299, '-black': 300, '-salami': 301, 'basiloni': 302, 'oiles': 303, '-broccolies': 304, '-extra': 305, '-artichokeses': 306, '-mushrooms': 307, '-blue': 308, 'hamoni': 309, '20': 310, 'fluid': 311, 'ounce': 312, 'chocolate': 313, 'in': 314, 'cans': 315, 'lemonade': 316, 'liter': 317, 'cappuccino': 318, '-liter': 319, 'kombucha': 320, 'ginger': 321, 'ale': 322, 'orange': 323, 'juice': 324, '200': 325, 'ml': 326, 'coffee': 327, 'sparkling': 328, 'water': 329, 'bottles': 330, 'smoothie': 331, '12': 332, 'bottle': 333, 'mocha': 334, 'cold': 335, 'brew': 336, '500': 337, '-milliliter': 338, 'herbal': 339, 'tea': 340, 'fl': 341, 'oz': 342, 'energy': 343, 'drink': 344, 'milkshake': 345, '8': 346, 'latte': 347, 'milliliter': 348, 'espresso': 349, 'eight': 350, '-ml': 351, 'frappuccino': 352, 'cola': 353, 'iced': 354, '16': 355, 'matcha': 356, 'americano': 357, 'sixteen': 358, 'pellegrinos': 359, 'diet': 360, 'lattes': 361, 'sprites': 362, 'ice': 363, 'teas': 364, 'sprite': 365, 'pepsis': 366, 'perrier': 367, 'milkshakes': 368, 'coke': 369, 'zeroes': 370, 'sodas': 371, 'seven': 372, 'ups': 373, 'fantas': 374, 'perriers': 375, 'lemon': 376, 'mountain': 377, 'dews': 378, 'doctor': 379, 'san': 380, 'pepers': 381, 'dr': 382, 'waters': 383, 'zeros': 384, 'pellegrino': 385, '7': 386, 'smoothies': 387, 'lemonades': 388, 'soda': 389, 'peper': 390, 'chocolates': 391, 'dew': 392, 'pepsi': 393, 'fanta': 394, 'up': 395, 'ales': 396, 'coffees': 397, 'juices': 398, 'americanos': 399, 'espressos': 400, 'colas': 401, 'drinks': 402, 'frappuccinos': 403, 'kombuchas': 404, 'brews': 405, 'mochas': 406, 'cappuccinos': 407, 'zero': 408, 'also': 409, 'cokes': 410, 'meatballs': 411, 'tunas': 412, 'onionsonis': 413, 'garliconis': 414, 'pineappleburger': 415, 'pepperses': 416, 'salamioni': 417, 'garliconi': 418, 'broccolionis': 419, 'chickenburger': 420, 'arugulaburger': 421, 'pineapplees': 422, 'tomatoesoni': 423, 'eggplantes': 424, '-arugula': 425, 'spinachoni': 426, 'spinachburger': 427, '-provolonees': 428, '-caramelized': 429, '-salamies': 430, '-arugulaes': 431, '-pepperoni': 432, 'sausageburger': 433, 'pepperoniburger': 434, '-bacones': 435, '-pineapplees': 436, 'spinachonis': 437, 'olivesburger': 438, 'bacononi': 439, 'onionsburger': 440, '-chorizo': 441, 'napolitan': 442, 'med': 443, 'oliveses': 444, 'anchoviesoni': 445, '-feta': 446, 'tomatoesburger': 447, 'artichokeses': 448, 'baconburger': 449, 'mushroomsoni': 450, 'hames': 451, 'artichokesburger': 452, 'provoloneburger': 453, 'pineappleonis': 454, '-prosciuttoes': 455, '-basil': 456, '-grilled': 457, 'artichokesonis': 458, 'nine': 459, '2': 460, 'six': 461, '13': 462, '6': 463, '14': 464, 'fifteen': 465, 'twelve': 466, 'ten': 467, '1': 468, 'thirteen': 469, '4': 470, '5': 471, 'fourteen': 472, 'eleven': 473, '11': 474, '3': 475, '15': 476, 'an': 477, '10': 478, '9': 479, 'chorizoonis': 480, 'mushroomsburger': 481, '-broccoli': 482, 'salamies': 483, 'anchoviesburger': 484, '-pineapple': 485, 'broccolioni': 486, 'pepperonionis': 487, 'chickenoni': 488, '-chorizoes': 489, '-bacon': 490, 'chickenonis': 491, '-sausage': 492, 'jalapenosonis': 493, 'salamionis': 494, 'provoloneonis': 495, 'basilonis': 496, 'tofuonis': 497, 'prosciuttoonis': 498, 'broccoliburger': 499, 'prosciuttoburger': 500, 'peppersburger': 501, '-onions': 502, 'sausageoni': 503, 'basilburger': 504, '-eggplant': 505, 'tomatoesonis': 506, 'to': 507, 'order': 508, '\"ll\"': 509, 'along': 510, 'but': 511, 'get': 512, 'would': 513, 'try': 514, 'please': 515, 'me': 516, 'you': 517, 'wanted': 518, 'go': 519, 'for': 520, 'wish': 521, 'on': 522, 'it': 523, 'could': 524, 'let': 525, 'there': 526, 'add': 527, 'feel': 528, 'trying': 529, 'some': 530, 'my': 531, 'today': 532, 'is': 533, 'make': 534, 'that': 535, '\"s\"': 536, 'put': 537, 'too': 538, 'thanks': 539, 'how': 540, 'are': 541, 'tonight': 542, 'as': 543, 'well': 544, 'appreciate': 545, 'place': 546, 'ill': 547, 'take': 548, 'do': 549, 'will': 550, 'think': 551, 'oh': 552, 'don': 553, '\"t\"': 554, 'leave': 555, 'off': 556, 'id': 557, 'top': 558, 'include': 559, 'has': 560, 'adding': 561, 'love': 562, 'favor': 563, 'fresh': 564, 'drizzle': 565, '-up': 566, 'give': 567, 'am': 568, 'wanting': 569, '\"m\"': 570, 'ordering': 571, 'comes': 572, 'sure': 573, 'skip': 574, 'though': 575, 'important': 576, 'allergic': 577, 'them': 578, 'guess': 579, 'good': 580, 'evening': 581, 'okay': 582, 'start': 583, 'includes': 584, 'this': 585, 'set': 586, 'beautiful': 587, 'additional': 588, 'won': 589, 'hey': 590, 'be': 591, 'great': 592, 'day': 593, 'definitely': 594, 'more': 595, 'bell': 596, 'prefer': 597, 'including': 598, 'see': 599, 'lets': 600, 'which': 601, 'then': 602, 'rush': 603, 'hello': 604, 'hamburger': 605, 'begin': 606}\n",
      "Model loaded from ../weights/Bilstm_order_sequence.pt\n",
      "Model loaded from ../weights/Bilstm_model2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yousi\\AppData\\Local\\Temp\\ipykernel_4128\\1166127925.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiLSTMModel(\n",
       "  (embedding): Embedding(607, 128, padding_idx=0)\n",
       "  (bilstm_1): LSTM(128, 128, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (fc2): Linear(in_features=256, out_features=40, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def load_vocab():\n",
    "    # loads the vocab from the text file \"vocab.txt\" and then swaps the key value pairs\n",
    "    with open(\"../dataset2/vocab.txt\", \"r\") as f:\n",
    "        vocab = f.readlines()\n",
    "    # remove any commas and single quotes\n",
    "    vocab = [v.replace(\",\", \"\").replace(\"'\", \"\") for v in vocab]\n",
    "    vocab = {v.split(\":\")[0].strip():int(v.split(\":\")[1].strip()) for v in vocab}\n",
    "    return vocab\n",
    "\n",
    "vocab = load_vocab()\n",
    "print(vocab)\n",
    "\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, num_layers=3, dropout=0.5):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        self.bilstm_1 = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc2 = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embedding layer\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        # BiLSTM layer\n",
    "        lstm_out, _ = self.bilstm_1(embedded)\n",
    "\n",
    "        output = self.fc2(lstm_out)\n",
    "        return F.log_softmax(output, dim=-1)\n",
    "\n",
    "input_dim = len(vocab) \n",
    "embedding_dim = 128  # len(vocab)\n",
    "hidden_dim = 128  # Hidden state size for LSTM          first was 256 for batch norm 150\n",
    "output_dim1 = 6  # Number of output classes\n",
    "output_dim2 = 40  # Number of output classes\n",
    "num_layers = 2  # Number of BiLSTM layers\n",
    "dropout = 0.3  # Dropout probability\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_1 = BiLSTMModel(input_dim, embedding_dim, hidden_dim, output_dim1, num_layers, dropout).to(device)\n",
    "model_2 = BiLSTMModel(input_dim, embedding_dim, hidden_dim, output_dim2, num_layers, dropout).to(device)\n",
    "\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    print(f\"Model loaded from {path}\")\n",
    "    return model\n",
    "\n",
    "# load the 2 models\n",
    "load_model(model_1, \"../weights/Bilstm_order_sequence.pt\")\n",
    "load_model(model_2, \"../weights/Bilstm_model2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'current_group' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[135], line 264\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n\u001b[1;32m--> 264\u001b[0m \u001b[43mprocess_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../dataset2/test_train.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[135], line 256\u001b[0m, in \u001b[0;36mprocess_dataset\u001b[1;34m(input_file)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m infile:\n\u001b[0;32m    255\u001b[0m     entry \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprocess_entry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    257\u001b[0m         correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    258\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[135], line 48\u001b[0m, in \u001b[0;36mprocess_entry\u001b[1;34m(entry)\u001b[0m\n\u001b[0;32m     45\u001b[0m second_model_labels \u001b[38;5;241m=\u001b[39m model_2_output\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# Ensure list of labels\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Generate TOP_DECOUPLED output\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m top_decoupled \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_top_decoupled\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_model_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecond_model_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Preprocess TOP to JSON format\u001b[39;00m\n\u001b[0;32m     51\u001b[0m predicted_json \u001b[38;5;241m=\u001b[39m preprocess(top_decoupled)\n",
      "Cell \u001b[1;32mIn[135], line 143\u001b[0m, in \u001b[0;36mgenerate_top_decoupled\u001b[1;34m(text, first_labels, second_labels)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m second_label_key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB-\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# Close the previous group if there is one\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m current_group:\n\u001b[1;32m--> 143\u001b[0m         \u001b[43mpositive_close_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     current_group \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: label_type, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [word]}\n\u001b[0;32m    146\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[135], line 94\u001b[0m, in \u001b[0;36mgenerate_top_decoupled.<locals>.positive_close_group\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpositive_close_group\u001b[39m():\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcurrent_group\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m         result\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Close the previous group\u001b[39;00m\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;66;03m# since this is positive, if the current top group is a not group close it as well\u001b[39;00m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'current_group' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "# Label maps for the models\n",
    "MODEL_1_LABEL_MAP = {\n",
    "    \"B-PIZZAORDER\": 1,\n",
    "    \"I-PIZZAORDER\": 2,\n",
    "    \"B-DRINKORDER\": 3,\n",
    "    \"I-DRINKORDER\": 4,\n",
    "    \"O\": 5\n",
    "}\n",
    "\n",
    "MODEL_2_LABEL_MAP = {\n",
    "    'B-DRINKTYPE': 1, 'I-DRINKTYPE': 2,\n",
    "    'B-SIZE': 3, 'I-SIZE': 4,\n",
    "    'B-NUMBER': 5, 'I-NUMBER': 6,\n",
    "    'B-CONTAINERTYPE': 7, 'I-CONTAINERTYPE': 8,\n",
    "    'B-COMPLEX_TOPPING': 9, 'I-COMPLEX_TOPPING': 10,\n",
    "    'B-TOPPING': 11, 'I-TOPPING': 12,\n",
    "    'B-NEG_TOPPING': 13, 'I-NEG_TOPPING': 14,\n",
    "    'B-NEG_STYLE': 15, 'I-NEG_STYLE': 16,\n",
    "    'B-STYLE': 17, 'I-STYLE': 18,\n",
    "    'B-QUANTITY': 19, 'I-QUANTITY': 20,\n",
    "    'O': 21\n",
    "}\n",
    "\n",
    "# Function to apply both models and get the TOP_DECOUPLED format\n",
    "def process_entry(entry):\n",
    "    src_text = entry[\"train.SRC\"]\n",
    "    true_top = entry[\"train.TOP\"]\n",
    "\n",
    "    # Tokenize and preprocess the input text\n",
    "    tokens = tokenize(src_text)\n",
    "    # Convert tokens to integers\n",
    "    tokens = tokens_to_ints(tokens, vocab)\n",
    "    # Convert to tensor\n",
    "    tokens = torch.tensor(tokens).unsqueeze(0).to(device)\n",
    "\n",
    "    # Get predictions from the first model\n",
    "    model_1_output = model_1(tokens)\n",
    "    first_model_labels = model_1_output.argmax(dim=-1).squeeze(0).tolist()  # Ensure list of labels\n",
    "\n",
    "    # Get predictions from the second model\n",
    "    model_2_output = model_2(tokens)\n",
    "    second_model_labels = model_2_output.argmax(dim=-1).squeeze(0).tolist()  # Ensure list of labels\n",
    "\n",
    "    # Generate TOP_DECOUPLED output\n",
    "    top_decoupled = generate_top_decoupled(src_text, first_model_labels, second_model_labels)\n",
    "\n",
    "    # Preprocess TOP to JSON format\n",
    "    predicted_json = preprocess(top_decoupled)\n",
    "    true_json = preprocess(true_top)\n",
    "    \n",
    "    with open(\"predicted_true.json\", \"a\") as f:\n",
    "        f.write(f\"true top: {true_top}\\n\") \n",
    "    \n",
    "    write_comparison_file(predicted_json, true_json, top_decoupled)\n",
    "\n",
    "    # Compare the predicted JSON with the ground truth JSON\n",
    "    return predicted_json == true_json\n",
    "\n",
    "def generate_top_decoupled(text, first_labels, second_labels):\n",
    "    words = text.split()\n",
    "    first_labels = first_labels[:len(words)]\n",
    "    second_labels = second_labels[:len(words)]\n",
    "    \n",
    "    # Debugging output\n",
    "    with open(\"predicted_true.json\", \"a\") as f:\n",
    "        f.write(str(words) + \"\\n\")\n",
    "        f.write(str([next(k for k, v in MODEL_1_LABEL_MAP.items() if v == l) for l in first_labels]) + \"\\n\")\n",
    "        f.write(str([next(k for k, v in MODEL_2_LABEL_MAP.items() if v == l) for l in second_labels]) + \"\\n\\n\") \n",
    "    \n",
    "    \n",
    "    result = [\"(ORDER\"]\n",
    "    current_order_type = None\n",
    "    current_group = None\n",
    "    open_groups = []  # To keep track of open groups for proper closing\n",
    "    \n",
    "    def negative_close_group():\n",
    "        if current_group is not None:\n",
    "            result.append(\")\")\n",
    "            if open_groups:\n",
    "                if open_groups:                 \n",
    "                    open_groups.pop()\n",
    "            # if we are closing a negative topping and the top group is a complex topping\n",
    "            # we close that as well\n",
    "            if current_group[\"type\"] == \"NEG_TOPPING\" or current_group[\"type\"] == \"TOPPING\" and open_groups[-1] == \"COMPLEX_TOPPING\":\n",
    "                result.append(\")\")\n",
    "                if open_groups:                 \n",
    "                    open_groups.pop()\n",
    "                current_group = None\n",
    "            \n",
    "    def positive_close_group():\n",
    "        if current_group is not None:\n",
    "            result.append(\")\")  # Close the previous group\n",
    "            # since this is positive, if the current top group is a not group close it as well\n",
    "            if current_group[\"type\"] == \"NEG_TOPPING\" or current_group[\"type\"] == \"NEG_STYLE\":\n",
    "                result.append(\")\")\n",
    "            if open_groups:                 \n",
    "                open_groups.pop()\n",
    "            # if we are closing a negative topping and the top group is a complex topping\n",
    "            # we close that as well\n",
    "            if current_group[\"type\"] == \"NEG_TOPPING\" or current_group[\"type\"] == \"TOPPING\" and open_groups[-1] == \"COMPLEX_TOPPING\":\n",
    "                result.append(\")\")\n",
    "                if open_groups:                 \n",
    "                    open_groups.pop()\n",
    "                current_group = None\n",
    "\n",
    "    for i, (word, first_label, second_label) in enumerate(zip(words, first_labels, second_labels)):\n",
    "        # Handle the first labels (ORDER type: PIZZAORDER, DRINKORDER)\n",
    "        if first_label in [MODEL_1_LABEL_MAP[\"B-PIZZAORDER\"], MODEL_1_LABEL_MAP[\"B-DRINKORDER\"]]:\n",
    "            if current_order_type is not None:\n",
    "                result.append(\")\")  # Close the previous order\n",
    "                if open_groups:                 \n",
    "                    open_groups.pop()  # Remove from open_groups stack\n",
    "            current_order_type = \"PIZZAORDER\" if first_label == MODEL_1_LABEL_MAP[\"B-PIZZAORDER\"] else \"DRINKORDER\"\n",
    "            result.append(f\"({current_order_type}\")\n",
    "            open_groups.append(current_order_type)\n",
    "\n",
    "        elif first_label == MODEL_1_LABEL_MAP[\"O\"] and current_order_type is not None:\n",
    "            result.append(\")\")  # Close the current order\n",
    "            if open_groups:                 \n",
    "                open_groups.pop()\n",
    "            current_order_type = None\n",
    "            \n",
    "        elif first_label == MODEL_1_LABEL_MAP[\"O\"] and current_order_type is None:\n",
    "            continue  # Skip the word if it's not part of an order\n",
    "\n",
    "        # Handle the second labels (attributes like NUMBER, SIZE, TOPPING, etc.)\n",
    "        if second_label != MODEL_2_LABEL_MAP[\"O\"]:\n",
    "            second_label_key = next(\n",
    "                (key for key, value in MODEL_2_LABEL_MAP.items() if value == second_label), None\n",
    "            )\n",
    "            if not second_label_key:\n",
    "                print(f\"Warning: Unexpected label {second_label} encountered for word '{word}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            label_type = second_label_key.split(\"-\")[-1]\n",
    "            if label_type not in [\"NEG_TOPPING\", \"NEG_STYLE\", \"QUANTITY\"]:\n",
    "                if second_label_key.startswith(\"B-\"):\n",
    "                    # Close the previous group if there is one\n",
    "                    if current_group:\n",
    "                        positive_close_group()\n",
    "                        \n",
    "                    current_group = {\"type\": label_type, \"content\": [word]}\n",
    "                    result.append(f\"({label_type} {word}\")\n",
    "                    open_groups.append(label_type)\n",
    "\n",
    "                elif second_label_key.startswith(\"I-\") and current_group and current_group[\"type\"] == label_type:\n",
    "                    current_group[\"content\"].append(word)\n",
    "                    result[-1] += f\" {word}\"  # Append to the last open group\n",
    "\n",
    "                elif second_label_key.startswith(\"I-\") and (not current_group or current_group[\"type\"] != label_type):\n",
    "                    print(f\"Warning: I- tag '{label_type}' for word '{word}' without preceding B- tag. Converting to B-.\")\n",
    "                    # Close the previous group if there is one\n",
    "                    if current_group:\n",
    "                        positive_close_group()\n",
    "                    current_group = {\"type\": label_type, \"content\": [word]}\n",
    "                    result.append(f\"({label_type} {word}\")\n",
    "                    open_groups.append(label_type)\n",
    "                    \n",
    "            # special handling for QUANTITY (COMPLEX_TOPPING)\n",
    "            elif label_type == \"QUANTITY\":\n",
    "                if second_label_key.startswith(\"B-\"):\n",
    "                    if current_group:\n",
    "                        positive_close_group()\n",
    "                    result.append(f\"(COMPLEX_TOPPING (QUANTITY {word}\")\n",
    "                    current_group = {\"type\": label_type, \"content\": [word]}\n",
    "                elif second_label_key.startswith(\"I-\") and current_group and current_group[\"type\"] == label_type:\n",
    "                    current_group[\"content\"].append(word)\n",
    "                    result[-1] += f\" {word}\"\n",
    "                elif second_label_key.startswith(\"I-\") and (not current_group or current_group[\"type\"] != label_type):\n",
    "                    if current_group:\n",
    "                        positive_close_group()\n",
    "                    print(f\"Warning: I- tag '{label_type}' for word '{word}' without preceding B- tag. Converting to B-.\")\n",
    "                    result.append(f\"(COMPLEX_TOPPING (QUANTITY {word}\")\n",
    "                    current_group = {\"type\": label_type, \"content\": [word]}\n",
    "                # we add this here and then if we pop a topping and find COMPLEX_TOPPING\n",
    "                # at the top we will close it\n",
    "                open_groups.append(\"COMPLEX_TOPPING\")\n",
    "                open_groups.append(label_type)\n",
    "            \n",
    "            # Special handling for NEG_TOPPING and NEG_STYLE\n",
    "            else:\n",
    "                if second_label_key.startswith(\"B-\"):\n",
    "                    if current_group:\n",
    "                        negative_close_group()\n",
    "                    result.append(f\"(NOT ({'TOPPING' if label_type == 'NEG_TOPPING' else 'STYLE'} {word}\")\n",
    "                    current_group = {\"type\": label_type, \"content\": [word]}\n",
    "                    open_groups.append(label_type)\n",
    "                elif second_label_key.startswith(\"I-\") and current_group and current_group[\"type\"] == label_type:\n",
    "                    current_group[\"content\"].append(word)\n",
    "                    result[-1] += f\" {word}\"  # Append to the last open group\n",
    "                elif second_label_key.startswith(\"I-\") and (not current_group or current_group[\"type\"] != label_type):\n",
    "                     # Close the previous group if there is one\n",
    "                    if current_group:\n",
    "                        negative_close_group()\n",
    "                    print(f\"Warning: I- tag '{label_type}' for word '{word}' without preceding B- tag. Converting to B-.\")\n",
    "                    result.append(f\"(NOT ({'TOPPING' if label_type == 'NEG_TOPPING' else 'STYLE'} {word}\")\n",
    "                    current_group = {\"type\": label_type, \"content\": [word]}\n",
    "                    open_groups.append(label_type)\n",
    "                    \n",
    "        # Handle O labels\n",
    "        else:\n",
    "            if current_group:\n",
    "                result.append(\")\")  # Close the current group\n",
    "                if open_groups:                 \n",
    "                    open_groups.pop()\n",
    "            current_group = None\n",
    "\n",
    "    # Close any remaining open groups\n",
    "    while open_groups:\n",
    "        result.append(\")\")\n",
    "        \n",
    "        if open_groups:                 \n",
    "            open_groups.pop()\n",
    "\n",
    "    result.append(\")\")  # Close the overall ORDER group\n",
    "    return \" \".join(result)\n",
    "\n",
    "# Updated JSON comparison file formatting\n",
    "def write_comparison_file(predicted_json, true_json, top_decoupled):\n",
    "    with open(\"predicted_true.json\", \"a\") as f:\n",
    "        # write top decoupled \n",
    "        f.write(f\"TOP_DECOUPLED: {top_decoupled}\\n\\n\")\n",
    "        # Format both JSONs side by side in a neat way\n",
    "        predicted_str = json.dumps(predicted_json, indent=2)\n",
    "        true_str = json.dumps(true_json, indent=2)\n",
    "\n",
    "        max_width = max(len(line) for line in predicted_str.splitlines()) + 5\n",
    "        max_lines = max(len(predicted_str.splitlines()), len(true_str.splitlines()))\n",
    "        \n",
    "        predicted_lines = predicted_str.splitlines()\n",
    "        true_lines = true_str.splitlines()\n",
    "\n",
    "        f.write(f\"{'-' * (max_width * 2)}\\n\")\n",
    "        f.write(f\"{'Predicted'.center(max_width)}{'True'.center(max_width)}\\n\")\n",
    "        f.write(f\"{'-' * (max_width * 2)}\\n\")\n",
    "        \n",
    "        for i in range(max_lines):\n",
    "            left = predicted_lines[i] if i < len(predicted_lines) else \"\"\n",
    "            right = true_lines[i] if i < len(true_lines) else \"\"\n",
    "            f.write(f\"{left:<{max_width}}{right:<{max_width}}\\n\")\n",
    "        \n",
    "        f.write(f\"{'-' * (max_width * 2)}\\n\")\n",
    "        f.write(f\"Match: {predicted_json == true_json}\\n\")\n",
    "        f.write(f\"{'-' * (max_width * 2)}\\n\\n\")\n",
    "\n",
    "# Main function to process the dataset\n",
    "def process_dataset(input_file):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Clear the debug file\n",
    "    open(\"predicted_true.json\", \"w\").close()\n",
    "\n",
    "    with open(input_file, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            entry = json.loads(line)\n",
    "            if process_entry(entry):\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "    accuracy = correct / total * 100 if total > 0 else 0\n",
    "    print(f\"Accuracy: {accuracy:.2f}% ({correct}/{total})\")\n",
    "    return accuracy\n",
    "\n",
    "process_dataset(\"../dataset2/test_train.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
