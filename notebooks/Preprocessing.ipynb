{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_path = '../dataset/PIZZA_train.json'\n",
    "test_path = '../dataset/PIZZA_dev.json'\n",
    "df = pd.read_json(train_path, lines=True)\n",
    "dev = pd.read_json(test_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train.SRC</th>\n",
       "      <th>train.EXR</th>\n",
       "      <th>train.TOP</th>\n",
       "      <th>train.TOP-DECOUPLED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2456446</td>\n",
       "      <td>2456446</td>\n",
       "      <td>2456446</td>\n",
       "      <td>2456446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2456446</td>\n",
       "      <td>694346</td>\n",
       "      <td>2456446</td>\n",
       "      <td>1425035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>can i have a large bbq pulled pork</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...</td>\n",
       "      <td>(ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...</td>\n",
       "      <td>(ORDER (PIZZAORDER (NUMBER three ) (NOT (TOPPI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 train.SRC  \\\n",
       "count                              2456446   \n",
       "unique                             2456446   \n",
       "top     can i have a large bbq pulled pork   \n",
       "freq                                     1   \n",
       "\n",
       "                                                train.EXR  \\\n",
       "count                                             2456446   \n",
       "unique                                             694346   \n",
       "top     (ORDER (PIZZAORDER (NUMBER 1 ) (SIZE PARTY_SIZ...   \n",
       "freq                                                 1999   \n",
       "\n",
       "                                                train.TOP  \\\n",
       "count                                             2456446   \n",
       "unique                                            2456446   \n",
       "top     (ORDER can i have (PIZZAORDER (NUMBER a ) (SIZ...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                      train.TOP-DECOUPLED  \n",
       "count                                             2456446  \n",
       "unique                                            1425035  \n",
       "top     (ORDER (PIZZAORDER (NUMBER three ) (NOT (TOPPI...  \n",
       "freq                                                  167  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want three pies with parmesan cheese and without any sauce\n",
      "(ORDER i want (PIZZAORDER (NUMBER three ) pies with (TOPPING parmesan cheese ) and without any (NOT (TOPPING sauce ) ) ) )\n",
      "i want to order two medium pizzas with sausage and black olives and two medium pizzas with pepperoni and extra cheese and three large pizzas with pepperoni and sausage\n"
     ]
    }
   ],
   "source": [
    "X_train = df['train.SRC']\n",
    "y_train = df['train.TOP']\n",
    "X_test = dev['dev.SRC']\n",
    "y_test = dev['dev.TOP']\n",
    "print(X_train[476368])\n",
    "print(y_train[476368])\n",
    "print(dev['dev.SRC'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         can i have a large bbq pulled pork\n",
       "1          large pie with green pepper and with extra pep...\n",
       "2                          i'd like a large vegetarian pizza\n",
       "3          party size stuffed crust pie with american che...\n",
       "4                    can i have one personal sized artichoke\n",
       "                                 ...                        \n",
       "2456441    i'd like a pizza with arugula ricotta cheese a...\n",
       "2456442    i'd like a pizza with yellow peppers fried oni...\n",
       "2456443    i'd like a pizza with olives roasted tomatoes ...\n",
       "2456444    i'd like a pizza with mozzarella jalapeno and ...\n",
       "2456445    i'd like a pizza with hot pepper pecorino chee...\n",
       "Name: train.SRC, Length: 2456446, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 335)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_str_1 = len(max(X_train, key=len))\n",
    "max_str_2 = len(y_train[y_train.str.len().idxmax()])\n",
    "max_str_1, max_str_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def tokenize_output(output):\n",
    "    \"\"\"\n",
    "    Tokenizes the structured output into meaningful tokens.\n",
    "    Example:\n",
    "        Input: \"(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (TOPPING bbq pulled pork ) ) )\"\n",
    "        Output: [\"(ORDER\", \"(PIZZAORDER\", \"(NUMBER\", \"a\", \"(SIZE\", \"large\", \"(TOPPING\", \"bbq\", \"pulled\", \"pork\", \")\", \")\", \")\", \")\"]\n",
    "    \"\"\"\n",
    "    tokens = re.findall(r\"\\(|\\)|\\w+|[^\\s()]+\", output)\n",
    "    return tokens\n",
    "\n",
    "def build_vocab(outputs):\n",
    "    \"\"\"\n",
    "    Builds a vocabulary from tokenized outputs.\n",
    "    \"\"\"\n",
    "    vocab = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2}  # Special tokens\n",
    "    i = 3\n",
    "    for output in outputs:\n",
    "        tokens = tokenize_output(output)\n",
    "        for token in tokens:\n",
    "            if token not in vocab:\n",
    "                vocab[token] = i\n",
    "                i += 1\n",
    "    return vocab\n",
    "def encode_outputs(outputs, vocab):\n",
    "    \"\"\"\n",
    "    Encodes tokenized outputs into sequences of integers.\n",
    "    \"\"\"\n",
    "    encoded = []\n",
    "    for output in outputs:\n",
    "        tokens = tokenize_output(output)\n",
    "        sequence = [vocab[\"<SOS>\"]] + [vocab[token] for token in tokens if token in vocab] + [vocab[\"<EOS>\"]]\n",
    "        encoded.append(sequence)\n",
    "    return encoded\n",
    "\n",
    "def pad_sequences_to_fixed_length(sequences, max_len):\n",
    "    \"\"\"\n",
    "    Pads sequences to a fixed length.\n",
    "    \"\"\"\n",
    "    return pad_sequences(sequences, maxlen=max_len, padding=\"post\", value=0)\n",
    "\n",
    "def decode_sequence(sequence, vocab):\n",
    "    \"\"\"\n",
    "    Decodes a sequence of integers back into the structured output string.\n",
    "    \"\"\"\n",
    "    inv_vocab = {v: k for k, v in vocab.items()}  # Reverse the vocabulary\n",
    "    tokens = [inv_vocab[idx] for idx in sequence if idx in inv_vocab and idx not in {vocab[\"<SOS>\"], vocab[\"<EOS>\"], vocab[\"<PAD>\"]}]\n",
    "\n",
    "    output = \" \".join(tokens)\n",
    "    output = output.replace(\" ( \", \" (\").replace(\"( \", \"(\") #.replace(\" )\", \")\")\n",
    "    return output\n",
    "\n",
    "def decode_sequence_2(sequence, vocab):\n",
    "    \"\"\"\n",
    "    Decodes a sequence of integers back into the structured output string.\n",
    "    \"\"\"\n",
    "    inv_vocab = {v: k for k, v in vocab.items()}  # Reverse the vocabulary\n",
    "    # sequence = sequence.cpu().tolist()  # Convert tensor to a list of integers\n",
    "    tokens = [inv_vocab.get(idx, \"\") for idx in sequence if idx > 0]  # Ignore unknown and put empty char\n",
    "    return \"\".join(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prepare_data(\n",
    "    X_train, y_train, X_test, y_test, max_len_1=20, max_len_2 = 20\n",
    "):\n",
    "\n",
    "    X_vocab = build_vocab(X_train)  # Build vocabulary from training outputs\n",
    "    X_train_encoded = encode_outputs(X_train, X_vocab)  # Encode training outputs\n",
    "    X_test_encoded = encode_outputs(X_test, X_vocab)  # Encode testing outputs\n",
    "    X_train_processed = pad_sequences_to_fixed_length(X_train_encoded, max_len_1)\n",
    "    X_test_processed = pad_sequences_to_fixed_length(X_test_encoded, max_len_1)\n",
    "\n",
    "    vocab = build_vocab(y_train)  # Build vocabulary from training outputs\n",
    "    y_train_encoded = encode_outputs(y_train, vocab)  # Encode training outputs\n",
    "    y_test_encoded = encode_outputs(y_test, vocab)  # Encode testing outputs\n",
    "    y_train_processed = pad_sequences_to_fixed_length(y_train_encoded, max_len_2)\n",
    "    y_test_processed = pad_sequences_to_fixed_length(y_test_encoded, max_len_2)\n",
    "\n",
    "\n",
    "    return (\n",
    "        X_train_processed,\n",
    "        X_test_processed,\n",
    "        y_train_processed,\n",
    "        y_test_processed,\n",
    "        X_vocab,\n",
    "        vocab,  # Return vocabulary for decoding\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed, X_test_processed, y_train_processed, y_test_processed, X_vocab, vocab = prepare_data( X_train, y_train, X_test, y_test,max_len_1=250, max_len_2=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "del dev\n",
    "del X_train\n",
    "del X_test\n",
    "del y_train\n",
    "del y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<SOS>': 1,\n",
       " '<EOS>': 2,\n",
       " 'can': 3,\n",
       " 'i': 4,\n",
       " 'have': 5,\n",
       " 'a': 6,\n",
       " 'large': 7,\n",
       " 'bbq': 8,\n",
       " 'pulled': 9,\n",
       " 'pork': 10,\n",
       " 'pie': 11,\n",
       " 'with': 12,\n",
       " 'green': 13,\n",
       " 'pepper': 14,\n",
       " 'and': 15,\n",
       " 'extra': 16,\n",
       " 'peperonni': 17,\n",
       " \"'d\": 18,\n",
       " 'like': 19,\n",
       " 'vegetarian': 20,\n",
       " 'pizza': 21,\n",
       " 'party': 22,\n",
       " 'size': 23,\n",
       " 'stuffed': 24,\n",
       " 'crust': 25,\n",
       " 'american': 26,\n",
       " 'cheese': 27,\n",
       " 'mushroom': 28,\n",
       " 'one': 29,\n",
       " 'personal': 30,\n",
       " 'sized': 31,\n",
       " 'artichoke': 32,\n",
       " 'banana': 33,\n",
       " 'peppperonis': 34,\n",
       " 'low': 35,\n",
       " 'fat': 36,\n",
       " 'want': 37,\n",
       " 'regular': 38,\n",
       " 'without': 39,\n",
       " 'any': 40,\n",
       " 'fried': 41,\n",
       " 'onions': 42,\n",
       " 'little': 43,\n",
       " 'bit': 44,\n",
       " 'of': 45,\n",
       " 'high': 46,\n",
       " 'rise': 47,\n",
       " 'dough': 48,\n",
       " 'lot': 49,\n",
       " 'olive': 50,\n",
       " 'pesto': 51,\n",
       " 'sauce': 52,\n",
       " 'peperonis': 53,\n",
       " 'yellow': 54,\n",
       " 'meatball': 55,\n",
       " '-': 56,\n",
       " 'bean': 57,\n",
       " 'big': 58,\n",
       " 'meat': 59,\n",
       " 'mushrooms': 60,\n",
       " 'pecorino': 61,\n",
       " 'balsamic': 62,\n",
       " 'glaze': 63,\n",
       " 'black': 64,\n",
       " 'chicken': 65,\n",
       " 'mozzarella': 66,\n",
       " 'italian': 67,\n",
       " 'sausage': 68,\n",
       " 'olives': 69,\n",
       " 'pestos': 70,\n",
       " 'lunch': 71,\n",
       " 'alfredo': 72,\n",
       " 'need': 73,\n",
       " 'cheeseburger': 74,\n",
       " 'combination': 75,\n",
       " 'spiced': 76,\n",
       " 'mediterranean': 77,\n",
       " 'caramelized': 78,\n",
       " 'red': 79,\n",
       " 'no': 80,\n",
       " 'apple': 81,\n",
       " 'wood': 82,\n",
       " 'bacon': 83,\n",
       " 'chorrizo': 84,\n",
       " 'vegan': 85,\n",
       " 'pepperoni': 86,\n",
       " 'peperroni': 87,\n",
       " 'peppers': 88,\n",
       " 'not': 89,\n",
       " 'much': 90,\n",
       " 'basil': 91,\n",
       " 'feta': 92,\n",
       " 'medium': 93,\n",
       " 'cumin': 94,\n",
       " 'pickles': 95,\n",
       " 'peperronni': 96,\n",
       " 'meatlover': 97,\n",
       " 'small': 98,\n",
       " 'anchovies': 99,\n",
       " 'buffalo': 100,\n",
       " 'peppperoni': 101,\n",
       " 'hot': 102,\n",
       " 'carrot': 103,\n",
       " 'dried': 104,\n",
       " 'all': 105,\n",
       " 'artichokes': 106,\n",
       " 'peperoni': 107,\n",
       " 'parmesan': 108,\n",
       " 'gluten': 109,\n",
       " '-free': 110,\n",
       " 'garlic': 111,\n",
       " 'powder': 112,\n",
       " 'broccoli': 113,\n",
       " 'grilled': 114,\n",
       " 'deepdish': 115,\n",
       " 'mozarella': 116,\n",
       " 'crusts': 117,\n",
       " 'meatlovers': 118,\n",
       " 'everything': 119,\n",
       " 'carrots': 120,\n",
       " 'arugula': 121,\n",
       " 'pineapple': 122,\n",
       " 'kalamata': 123,\n",
       " 'thick': 124,\n",
       " 'beef': 125,\n",
       " 'bacons': 126,\n",
       " 'balzamic': 127,\n",
       " 'new': 128,\n",
       " 'york': 129,\n",
       " 'style': 130,\n",
       " 'every': 131,\n",
       " 'just': 132,\n",
       " 'pepperonis': 133,\n",
       " 'yorker': 134,\n",
       " 'tomato': 135,\n",
       " 'applewood': 136,\n",
       " 'ham': 137,\n",
       " 'barbecue': 138,\n",
       " 'margherita': 139,\n",
       " 'cheddar': 140,\n",
       " 'onion': 141,\n",
       " 'flakes': 142,\n",
       " 'white': 143,\n",
       " 'anchovy': 144,\n",
       " 'only': 145,\n",
       " 'bay': 146,\n",
       " 'leaves': 147,\n",
       " 'chickens': 148,\n",
       " 'roasted': 149,\n",
       " 'cauliflower': 150,\n",
       " 'lettuce': 151,\n",
       " 'salami': 152,\n",
       " 'free': 153,\n",
       " 'pickle': 154,\n",
       " 'veggie': 155,\n",
       " 'lots': 156,\n",
       " 'hams': 157,\n",
       " 'neapolitan': 158,\n",
       " 'brocoli': 159,\n",
       " 'tomatoes': 160,\n",
       " 'sourdough': 161,\n",
       " 'oregano': 162,\n",
       " 'ranch': 163,\n",
       " 'margarita': 164,\n",
       " 'pea': 165,\n",
       " 'the': 166,\n",
       " 'vegetables': 167,\n",
       " 'ground': 168,\n",
       " 'peas': 169,\n",
       " 'lovers': 170,\n",
       " 'works': 171,\n",
       " 'cherry': 172,\n",
       " 'jalapeno': 173,\n",
       " 'chicago': 174,\n",
       " 'hawaiian': 175,\n",
       " 'tiny': 176,\n",
       " 'pineapples': 177,\n",
       " 'thin': 178,\n",
       " 'spicy': 179,\n",
       " 'chorizo': 180,\n",
       " 'supreme': 181,\n",
       " 'tuna': 182,\n",
       " 'shrimps': 183,\n",
       " 'jalapenos': 184,\n",
       " 'veggies': 185,\n",
       " 'napolitana': 186,\n",
       " 'parsley': 187,\n",
       " 'rosemary': 188,\n",
       " 'keto': 189,\n",
       " 'ricotta': 190,\n",
       " 'mexican': 191,\n",
       " 'spinach': 192,\n",
       " 'pineaple': 193,\n",
       " 'oil': 194,\n",
       " 'beans': 195,\n",
       " 'shrimp': 196,\n",
       " 'pineaples': 197,\n",
       " 'lover': 198,\n",
       " 'topping': 199,\n",
       " 'flake': 200,\n",
       " 'many': 201,\n",
       " 'deep': 202,\n",
       " 'dish': 203,\n",
       " 'toppings': 204,\n",
       " 'two': 205,\n",
       " 'pizzas': 206,\n",
       " 'avoid': 207,\n",
       " 'three': 208,\n",
       " 'hold': 209,\n",
       " 'four': 210,\n",
       " 'pies': 211,\n",
       " 'hate': 212,\n",
       " 'five': 213,\n",
       " 'liter': 214,\n",
       " 'ice': 215,\n",
       " 'teas': 216,\n",
       " 'in': 217,\n",
       " 'cans': 218,\n",
       " '500': 219,\n",
       " '-milliliter': 220,\n",
       " '7': 221,\n",
       " 'ups': 222,\n",
       " 'bottles': 223,\n",
       " '20': 224,\n",
       " 'fluid': 225,\n",
       " 'ounce': 226,\n",
       " 'iced': 227,\n",
       " 'coke': 228,\n",
       " '200': 229,\n",
       " 'ml': 230,\n",
       " 'mountain': 231,\n",
       " 'dews': 232,\n",
       " 'lemon': 233,\n",
       " 'tea': 234,\n",
       " 'doctor': 235,\n",
       " 'sprite': 236,\n",
       " 'fl': 237,\n",
       " 'oz': 238,\n",
       " 'diet': 239,\n",
       " 'coffees': 240,\n",
       " '8': 241,\n",
       " 'pepsi': 242,\n",
       " 'pellegrino': 243,\n",
       " '-liter': 244,\n",
       " 'san': 245,\n",
       " 'bottle': 246,\n",
       " 'dr': 247,\n",
       " 'peper': 248,\n",
       " 'soda': 249,\n",
       " 'sixteen': 250,\n",
       " 'cokes': 251,\n",
       " '-ml': 252,\n",
       " 'eight': 253,\n",
       " 'fanta': 254,\n",
       " '12': 255,\n",
       " 'up': 256,\n",
       " 'sprites': 257,\n",
       " 'fantas': 258,\n",
       " 'zeros': 259,\n",
       " 'coffee': 260,\n",
       " 'pepsis': 261,\n",
       " 'pepers': 262,\n",
       " 'milliliter': 263,\n",
       " 'dew': 264,\n",
       " 'zero': 265,\n",
       " 'perriers': 266,\n",
       " 'perrier': 267,\n",
       " 'water': 268,\n",
       " 'sodas': 269,\n",
       " 'pellegrinos': 270,\n",
       " '16': 271,\n",
       " 'seven': 272,\n",
       " 'ginger': 273,\n",
       " 'ale': 274,\n",
       " 'ales': 275,\n",
       " 'waters': 276,\n",
       " 'zeroes': 277,\n",
       " 'also': 278,\n",
       " 'meatballs': 279,\n",
       " 'sausages': 280,\n",
       " 'tunas': 281,\n",
       " 'napolitan': 282,\n",
       " 'pan': 283,\n",
       " 'med': 284,\n",
       " 'nine': 285,\n",
       " '2': 286,\n",
       " 'six': 287,\n",
       " '13': 288,\n",
       " 'ten': 289,\n",
       " '6': 290,\n",
       " '14': 291,\n",
       " 'eleven': 292,\n",
       " '10': 293,\n",
       " 'an': 294,\n",
       " 'twelve': 295,\n",
       " '3': 296,\n",
       " 'fifteen': 297,\n",
       " '1': 298,\n",
       " 'thirteen': 299,\n",
       " '4': 300,\n",
       " '5': 301,\n",
       " 'fourteen': 302,\n",
       " '11': 303,\n",
       " '9': 304,\n",
       " '15': 305}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<SOS>': 1,\n",
       " '<EOS>': 2,\n",
       " '(': 3,\n",
       " 'ORDER': 4,\n",
       " 'can': 5,\n",
       " 'i': 6,\n",
       " 'have': 7,\n",
       " 'PIZZAORDER': 8,\n",
       " 'NUMBER': 9,\n",
       " 'a': 10,\n",
       " ')': 11,\n",
       " 'SIZE': 12,\n",
       " 'large': 13,\n",
       " 'TOPPING': 14,\n",
       " 'bbq': 15,\n",
       " 'pulled': 16,\n",
       " 'pork': 17,\n",
       " 'pie': 18,\n",
       " 'with': 19,\n",
       " 'green': 20,\n",
       " 'pepper': 21,\n",
       " 'and': 22,\n",
       " 'COMPLEX_TOPPING': 23,\n",
       " 'QUANTITY': 24,\n",
       " 'extra': 25,\n",
       " 'peperonni': 26,\n",
       " \"'d\": 27,\n",
       " 'like': 28,\n",
       " 'STYLE': 29,\n",
       " 'vegetarian': 30,\n",
       " 'pizza': 31,\n",
       " 'party': 32,\n",
       " 'size': 33,\n",
       " 'stuffed': 34,\n",
       " 'crust': 35,\n",
       " 'american': 36,\n",
       " 'cheese': 37,\n",
       " 'mushroom': 38,\n",
       " 'one': 39,\n",
       " 'personal': 40,\n",
       " 'sized': 41,\n",
       " 'artichoke': 42,\n",
       " 'banana': 43,\n",
       " 'peppperonis': 44,\n",
       " 'low': 45,\n",
       " 'fat': 46,\n",
       " 'want': 47,\n",
       " 'regular': 48,\n",
       " 'without': 49,\n",
       " 'any': 50,\n",
       " 'NOT': 51,\n",
       " 'fried': 52,\n",
       " 'onions': 53,\n",
       " 'little': 54,\n",
       " 'bit': 55,\n",
       " 'of': 56,\n",
       " 'high': 57,\n",
       " 'rise': 58,\n",
       " 'dough': 59,\n",
       " 'lot': 60,\n",
       " 'olive': 61,\n",
       " 'pesto': 62,\n",
       " 'sauce': 63,\n",
       " 'peperonis': 64,\n",
       " 'yellow': 65,\n",
       " 'meatball': 66,\n",
       " '-': 67,\n",
       " 'bean': 68,\n",
       " 'big': 69,\n",
       " 'meat': 70,\n",
       " 'mushrooms': 71,\n",
       " 'pecorino': 72,\n",
       " 'balsamic': 73,\n",
       " 'glaze': 74,\n",
       " 'black': 75,\n",
       " 'chicken': 76,\n",
       " 'mozzarella': 77,\n",
       " 'italian': 78,\n",
       " 'sausage': 79,\n",
       " 'olives': 80,\n",
       " 'pestos': 81,\n",
       " 'lunch': 82,\n",
       " 'alfredo': 83,\n",
       " 'need': 84,\n",
       " 'cheeseburger': 85,\n",
       " 'combination': 86,\n",
       " 'spiced': 87,\n",
       " 'mediterranean': 88,\n",
       " 'caramelized': 89,\n",
       " 'red': 90,\n",
       " 'no': 91,\n",
       " 'apple': 92,\n",
       " 'wood': 93,\n",
       " 'bacon': 94,\n",
       " 'chorrizo': 95,\n",
       " 'vegan': 96,\n",
       " 'pepperoni': 97,\n",
       " 'peperroni': 98,\n",
       " 'peppers': 99,\n",
       " 'not': 100,\n",
       " 'much': 101,\n",
       " 'basil': 102,\n",
       " 'feta': 103,\n",
       " 'medium': 104,\n",
       " 'cumin': 105,\n",
       " 'pickles': 106,\n",
       " 'peperronni': 107,\n",
       " 'meatlover': 108,\n",
       " 'small': 109,\n",
       " 'anchovies': 110,\n",
       " 'buffalo': 111,\n",
       " 'peppperoni': 112,\n",
       " 'hot': 113,\n",
       " 'carrot': 114,\n",
       " 'dried': 115,\n",
       " 'all': 116,\n",
       " 'artichokes': 117,\n",
       " 'peperoni': 118,\n",
       " 'parmesan': 119,\n",
       " 'gluten': 120,\n",
       " '-free': 121,\n",
       " 'garlic': 122,\n",
       " 'powder': 123,\n",
       " 'broccoli': 124,\n",
       " 'grilled': 125,\n",
       " 'deepdish': 126,\n",
       " 'mozarella': 127,\n",
       " 'crusts': 128,\n",
       " 'meatlovers': 129,\n",
       " 'everything': 130,\n",
       " 'carrots': 131,\n",
       " 'arugula': 132,\n",
       " 'pineapple': 133,\n",
       " 'kalamata': 134,\n",
       " 'thick': 135,\n",
       " 'beef': 136,\n",
       " 'bacons': 137,\n",
       " 'balzamic': 138,\n",
       " 'new': 139,\n",
       " 'york': 140,\n",
       " 'style': 141,\n",
       " 'every': 142,\n",
       " 'just': 143,\n",
       " 'pepperonis': 144,\n",
       " 'yorker': 145,\n",
       " 'tomato': 146,\n",
       " 'applewood': 147,\n",
       " 'ham': 148,\n",
       " 'barbecue': 149,\n",
       " 'margherita': 150,\n",
       " 'cheddar': 151,\n",
       " 'onion': 152,\n",
       " 'flakes': 153,\n",
       " 'white': 154,\n",
       " 'anchovy': 155,\n",
       " 'only': 156,\n",
       " 'bay': 157,\n",
       " 'leaves': 158,\n",
       " 'chickens': 159,\n",
       " 'roasted': 160,\n",
       " 'cauliflower': 161,\n",
       " 'lettuce': 162,\n",
       " 'salami': 163,\n",
       " 'free': 164,\n",
       " 'pickle': 165,\n",
       " 'veggie': 166,\n",
       " 'lots': 167,\n",
       " 'hams': 168,\n",
       " 'neapolitan': 169,\n",
       " 'brocoli': 170,\n",
       " 'tomatoes': 171,\n",
       " 'sourdough': 172,\n",
       " 'oregano': 173,\n",
       " 'ranch': 174,\n",
       " 'margarita': 175,\n",
       " 'pea': 176,\n",
       " 'the': 177,\n",
       " 'vegetables': 178,\n",
       " 'ground': 179,\n",
       " 'peas': 180,\n",
       " 'lovers': 181,\n",
       " 'works': 182,\n",
       " 'cherry': 183,\n",
       " 'jalapeno': 184,\n",
       " 'chicago': 185,\n",
       " 'hawaiian': 186,\n",
       " 'tiny': 187,\n",
       " 'pineapples': 188,\n",
       " 'thin': 189,\n",
       " 'spicy': 190,\n",
       " 'chorizo': 191,\n",
       " 'supreme': 192,\n",
       " 'tuna': 193,\n",
       " 'shrimps': 194,\n",
       " 'jalapenos': 195,\n",
       " 'veggies': 196,\n",
       " 'napolitana': 197,\n",
       " 'parsley': 198,\n",
       " 'rosemary': 199,\n",
       " 'keto': 200,\n",
       " 'ricotta': 201,\n",
       " 'mexican': 202,\n",
       " 'spinach': 203,\n",
       " 'pineaple': 204,\n",
       " 'oil': 205,\n",
       " 'beans': 206,\n",
       " 'shrimp': 207,\n",
       " 'pineaples': 208,\n",
       " 'lover': 209,\n",
       " 'topping': 210,\n",
       " 'flake': 211,\n",
       " 'many': 212,\n",
       " 'deep': 213,\n",
       " 'dish': 214,\n",
       " 'toppings': 215,\n",
       " 'two': 216,\n",
       " 'pizzas': 217,\n",
       " 'avoid': 218,\n",
       " 'three': 219,\n",
       " 'hold': 220,\n",
       " 'four': 221,\n",
       " 'pies': 222,\n",
       " 'hate': 223,\n",
       " 'five': 224,\n",
       " 'DRINKORDER': 225,\n",
       " 'VOLUME': 226,\n",
       " 'liter': 227,\n",
       " 'DRINKTYPE': 228,\n",
       " 'ice': 229,\n",
       " 'teas': 230,\n",
       " 'CONTAINERTYPE': 231,\n",
       " 'in': 232,\n",
       " 'cans': 233,\n",
       " '500': 234,\n",
       " '-milliliter': 235,\n",
       " '7': 236,\n",
       " 'ups': 237,\n",
       " 'bottles': 238,\n",
       " '20': 239,\n",
       " 'fluid': 240,\n",
       " 'ounce': 241,\n",
       " 'iced': 242,\n",
       " 'coke': 243,\n",
       " '200': 244,\n",
       " 'ml': 245,\n",
       " 'mountain': 246,\n",
       " 'dews': 247,\n",
       " 'lemon': 248,\n",
       " 'tea': 249,\n",
       " 'doctor': 250,\n",
       " 'sprite': 251,\n",
       " 'fl': 252,\n",
       " 'oz': 253,\n",
       " 'diet': 254,\n",
       " 'coffees': 255,\n",
       " '8': 256,\n",
       " 'pepsi': 257,\n",
       " 'pellegrino': 258,\n",
       " '-liter': 259,\n",
       " 'san': 260,\n",
       " 'bottle': 261,\n",
       " 'dr': 262,\n",
       " 'peper': 263,\n",
       " 'soda': 264,\n",
       " 'sixteen': 265,\n",
       " 'cokes': 266,\n",
       " '-ml': 267,\n",
       " 'eight': 268,\n",
       " 'fanta': 269,\n",
       " '12': 270,\n",
       " 'up': 271,\n",
       " 'sprites': 272,\n",
       " 'fantas': 273,\n",
       " 'zeros': 274,\n",
       " 'coffee': 275,\n",
       " 'pepsis': 276,\n",
       " 'pepers': 277,\n",
       " 'milliliter': 278,\n",
       " 'dew': 279,\n",
       " 'zero': 280,\n",
       " 'perriers': 281,\n",
       " 'perrier': 282,\n",
       " 'water': 283,\n",
       " 'sodas': 284,\n",
       " 'pellegrinos': 285,\n",
       " '16': 286,\n",
       " 'seven': 287,\n",
       " 'ginger': 288,\n",
       " 'ale': 289,\n",
       " 'ales': 290,\n",
       " 'waters': 291,\n",
       " 'zeroes': 292,\n",
       " 'also': 293,\n",
       " 'meatballs': 294,\n",
       " 'sausages': 295,\n",
       " 'tunas': 296,\n",
       " 'napolitan': 297,\n",
       " 'pan': 298,\n",
       " 'med': 299,\n",
       " 'nine': 300,\n",
       " '2': 301,\n",
       " 'six': 302,\n",
       " '13': 303,\n",
       " 'ten': 304,\n",
       " '6': 305,\n",
       " '14': 306,\n",
       " 'eleven': 307,\n",
       " '10': 308,\n",
       " 'an': 309,\n",
       " 'twelve': 310,\n",
       " '3': 311,\n",
       " 'fifteen': 312,\n",
       " '1': 313,\n",
       " 'thirteen': 314,\n",
       " '4': 315,\n",
       " '5': 316,\n",
       " 'fourteen': 317,\n",
       " '11': 318,\n",
       " '9': 319,\n",
       " '15': 320}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save SRC as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data = [entry for entry in X_train ]\n",
    "with open(\"../dataset/src_data.txt\", \"w\") as src_file:\n",
    "    src_file.write(\"\\n\".join(src_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn TOP-DECOUPLED into json tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full input text: (ORDER (PIZZAORDER (NUMBER one) (SIZE large) (STYLE thin crust) (TOPPING cheese) (TOPPING pepperoni) ) (PIZZAORDER (NUMBER two) (SIZE medium) (STYLE deep dish) (NOT (TOPPING mushrooms) ) (COMPLEX_TOPPING (QUANTITY extra) (TOPPING olives) ) ) (DRINKORDER (NUMBER five) (VOLUME one liter) (DRINKTYPE lemon ice tea) (CONTAINERTYPE bottles) )(DRINKORDER (NUMBER three) (VOLUME two liters) (DRINKTYPE cola) (CONTAINERTYPE cans) ) (DRINKORDER (NUMBER three) (VOLUME two liters) (DRINKTYPE cola) (CONTAINERTYPE cans) ) )\n",
      "Found order elements: ['(PIZZAORDER (NUMBER one) (SIZE large) (STYLE thin crust) (TOPPING cheese) (TOPPING pepperoni) )', '(PIZZAORDER (NUMBER two) (SIZE medium) (STYLE deep dish) (NOT (TOPPING mushrooms) ) (COMPLEX_TOPPING (QUANTITY extra) (TOPPING olives) ) )', '(DRINKORDER (NUMBER five) (VOLUME one liter) (DRINKTYPE lemon ice tea) (CONTAINERTYPE bottles) )', '(DRINKORDER (NUMBER three) (VOLUME two liters) (DRINKTYPE cola) (CONTAINERTYPE cans) )', '(DRINKORDER (NUMBER three) (VOLUME two liters) (DRINKTYPE cola) (CONTAINERTYPE cans) )']\n",
      "Parsing element: (PIZZAORDER (NUMBER one) (SIZE large) (STYLE thin crust) (TOPPING cheese) (TOPPING pepperoni) )\n",
      "Parts found: ['PIZZAORDER', 'NUMBER one', 'SIZE large', 'STYLE thin crust', 'TOPPING cheese', 'TOPPING pepperoni']\n",
      "Processing token: NUMBER one\n",
      "Processing token: SIZE large\n",
      "Processing token: STYLE thin crust\n",
      "Processing token: TOPPING cheese\n",
      "Processing token: TOPPING pepperoni\n",
      "Parsing element: (PIZZAORDER (NUMBER two) (SIZE medium) (STYLE deep dish) (NOT (TOPPING mushrooms) ) (COMPLEX_TOPPING (QUANTITY extra) (TOPPING olives) ) )\n",
      "Parts found: ['PIZZAORDER', 'NUMBER two', 'SIZE medium', 'STYLE deep dish', 'TOPPING mushrooms', 'QUANTITY extra', 'TOPPING olives']\n",
      "Processing token: NUMBER two\n",
      "Processing token: SIZE medium\n",
      "Processing token: STYLE deep dish\n",
      "Processing token: TOPPING mushrooms\n",
      "Processing token: QUANTITY extra\n",
      "Processing token: TOPPING olives\n",
      "Parsing element: (DRINKORDER (NUMBER five) (VOLUME one liter) (DRINKTYPE lemon ice tea) (CONTAINERTYPE bottles) )\n",
      "Parts found: ['DRINKORDER', 'NUMBER five', 'VOLUME one liter', 'DRINKTYPE lemon ice tea', 'CONTAINERTYPE bottles']\n",
      "Processing drink token: NUMBER five\n",
      "Processing drink token: VOLUME one liter\n",
      "Processing drink token: DRINKTYPE lemon ice tea\n",
      "Processing drink token: CONTAINERTYPE bottles\n",
      "Parsing element: (DRINKORDER (NUMBER three) (VOLUME two liters) (DRINKTYPE cola) (CONTAINERTYPE cans) )\n",
      "Parts found: ['DRINKORDER', 'NUMBER three', 'VOLUME two liters', 'DRINKTYPE cola', 'CONTAINERTYPE cans']\n",
      "Processing drink token: NUMBER three\n",
      "Processing drink token: VOLUME two liters\n",
      "Processing drink token: DRINKTYPE cola\n",
      "Processing drink token: CONTAINERTYPE cans\n",
      "Parsing element: (DRINKORDER (NUMBER three) (VOLUME two liters) (DRINKTYPE cola) (CONTAINERTYPE cans) )\n",
      "Parts found: ['DRINKORDER', 'NUMBER three', 'VOLUME two liters', 'DRINKTYPE cola', 'CONTAINERTYPE cans']\n",
      "Processing drink token: NUMBER three\n",
      "Processing drink token: VOLUME two liters\n",
      "Processing drink token: DRINKTYPE cola\n",
      "Processing drink token: CONTAINERTYPE cans\n",
      "{\n",
      "  \"ORDER\": {\n",
      "    \"PIZZAORDER\": [\n",
      "      {\n",
      "        \"NUMBER\": \"one\",\n",
      "        \"SIZE\": \"large\",\n",
      "        \"STYLE\": \"thin crust\",\n",
      "        \"AllTopping\": [\n",
      "          {\n",
      "            \"NOT\": false,\n",
      "            \"Quantity\": null,\n",
      "            \"Topping\": \"cheese\"\n",
      "          },\n",
      "          {\n",
      "            \"NOT\": false,\n",
      "            \"Quantity\": null,\n",
      "            \"Topping\": \"pepperoni\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"NUMBER\": \"two\",\n",
      "        \"SIZE\": \"medium\",\n",
      "        \"STYLE\": \"deep dish\",\n",
      "        \"AllTopping\": [\n",
      "          {\n",
      "            \"NOT\": false,\n",
      "            \"Quantity\": null,\n",
      "            \"Topping\": \"mushrooms\"\n",
      "          },\n",
      "          {\n",
      "            \"NOT\": false,\n",
      "            \"Quantity\": null,\n",
      "            \"Topping\": \"olives\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"DRINKORDER\": [\n",
      "      {\n",
      "        \"NUMBER\": \"five\",\n",
      "        \"VOLUME\": \"one liter\",\n",
      "        \"DRINKTYPE\": \"lemon ice tea\",\n",
      "        \"CONTAINERTYPE\": \"bottles\"\n",
      "      },\n",
      "      {\n",
      "        \"NUMBER\": \"three\",\n",
      "        \"VOLUME\": \"two liters\",\n",
      "        \"DRINKTYPE\": \"cola\",\n",
      "        \"CONTAINERTYPE\": \"cans\"\n",
      "      },\n",
      "      {\n",
      "        \"NUMBER\": \"three\",\n",
      "        \"VOLUME\": \"two liters\",\n",
      "        \"DRINKTYPE\": \"cola\",\n",
      "        \"CONTAINERTYPE\": \"cans\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def parse_order(input_text):\n",
    "    def parse_element(element):\n",
    "        print(f\"Parsing element: {element}\")\n",
    "        \n",
    "        # Helper function to parse individual elements\n",
    "        matches = re.findall(r'\\b(PIZZAORDER|DRINKORDER)\\b|(?:\\b([A-Z]+)\\s([^()]+)\\b)', element)\n",
    "        parts = [match[0] or f\"{match[1]} {match[2]}\" for match in matches]\n",
    "\n",
    "        print(f\"Parts found: {parts}\")\n",
    "\n",
    "        if parts[0] == 'PIZZAORDER':\n",
    "\n",
    "            pizza = {\n",
    "                'NUMBER': None, \n",
    "                'SIZE': None, \n",
    "                'STYLE': None, \n",
    "                'AllTopping': []\n",
    "            }\n",
    "            for token in parts[1:]:\n",
    "\n",
    "                print(f\"Processing token: {token}\") \n",
    "\n",
    "                if token.startswith('NUMBER'):\n",
    "                    pizza['NUMBER'] = ' '.join(token.split()[1:])\n",
    "                elif token.startswith('SIZE'):\n",
    "                    pizza['SIZE'] = ' '.join(token.split()[1:])\n",
    "                elif token.startswith('STYLE'):\n",
    "                    pizza['STYLE'] = ' '.join(token.split()[1:])\n",
    "                elif token.startswith('TOPPING'):\n",
    "                    pizza['AllTopping'].append({\n",
    "                        'NOT': False,\n",
    "                        'Quantity': None,\n",
    "                        'Topping': ' '.join(token.split()[1:])\n",
    "                    })\n",
    "                elif token.startswith('NOT'):\n",
    "                    pizza['AllTopping'].append({\n",
    "                        'NOT': True,\n",
    "                        'Quantity': None,\n",
    "                        'Topping': ' '.join(token.split()[1:])\n",
    "                    })\n",
    "                elif token.startswith('COMPLEX_TOPPING'):\n",
    "                    toppings = re.findall(r'\\(([^()]+)\\)', token)\n",
    "                    for t in toppings:\n",
    "                        t_tokens = t.split()\n",
    "                        pizza['AllTopping'].append({\n",
    "                            'NOT': False,\n",
    "                            'Quantity': t_tokens[1] if len(t_tokens) > 2 else None,\n",
    "                            'Topping': t_tokens[-1]# ' '.join(token.split()[-1:])\n",
    "                        })\n",
    "                \n",
    "            return pizza\n",
    "        \n",
    "        elif parts[0] == 'DRINKORDER':\n",
    "            drink = {\n",
    "                'NUMBER': None, \n",
    "                'VOLUME': None, \n",
    "                'DRINKTYPE': None, \n",
    "                'CONTAINERTYPE': None\n",
    "            }\n",
    "            for token in parts[1:]:\n",
    "                \n",
    "                print(f\"Processing drink token: {token}\")  \n",
    "\n",
    "                if token.startswith('NUMBER'):\n",
    "                    drink['NUMBER'] = token.split()[1]\n",
    "                elif token.startswith('VOLUME'):\n",
    "                    drink['VOLUME'] = ' '.join(token.split()[1:])\n",
    "                elif token.startswith('DRINKTYPE'):\n",
    "                    drink['DRINKTYPE'] = ' '.join(token.split()[1:])\n",
    "                elif token.startswith('CONTAINERTYPE'):\n",
    "                    drink['CONTAINERTYPE'] = ' '.join(token.split()[1:])\n",
    "                \n",
    "            return drink\n",
    "        \n",
    "        return None\n",
    "\n",
    "    # Initialize the base structure\n",
    "    order = {\"ORDER\": {\"PIZZAORDER\": [], \"DRINKORDER\": []}}\n",
    "    \n",
    "\n",
    "    print(f\"Full input text: {input_text}\")\n",
    "    \n",
    "\n",
    "    order_elements = [x.group() for x in  re.finditer(r'\\((?:PIZZAORDER|DRINKORDER)(?:[^()]*|\\((?:[^()]*|\\([^()]*\\))*\\))*\\)', input_text)]\n",
    "    \n",
    "    print(f\"Found order elements: {order_elements}\")  # Debug print\n",
    "    \n",
    "    for element in order_elements:\n",
    "        parsed = parse_element(element)\n",
    "        if parsed:\n",
    "            if 'SIZE' in parsed:\n",
    "                order['ORDER']['PIZZAORDER'].append(parsed)\n",
    "            elif 'VOLUME' in parsed:\n",
    "                order['ORDER']['DRINKORDER'].append(parsed)\n",
    "    \n",
    "    return order\n",
    "\n",
    "# Example usage\n",
    "input_text = '(ORDER (PIZZAORDER (NUMBER one) (SIZE large) (STYLE thin crust) (TOPPING cheese) (TOPPING pepperoni) ) (PIZZAORDER (NUMBER two) (SIZE medium) (STYLE deep dish) (NOT (TOPPING mushrooms) ) (COMPLEX_TOPPING (QUANTITY extra) (TOPPING olives) ) ) (DRINKORDER (NUMBER five) (VOLUME one liter) (DRINKTYPE lemon ice tea) (CONTAINERTYPE bottles) )(DRINKORDER (NUMBER three) (VOLUME two liters) (DRINKTYPE cola) (CONTAINERTYPE cans) ) (DRINKORDER (NUMBER three) (VOLUME two liters) (DRINKTYPE cola) (CONTAINERTYPE cans) ) )'\n",
    "\n",
    "result = parse_order(input_text)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ORDER\": {\"PIZZAORDER\": [{\"NUMBER\": \"fourteen\", \"SIZE\": null, \"STYLE\": null, \"AllTopping\": [{\"NOT\": false, \"Quantity\": null, \"Topping\": \"garlic powder\"}]}], \"DRINKORDER\": [{\"NUMBER\": \"6\", \"VOLUME\": null, \"DRINKTYPE\": \"diet ice teas\", \"CONTAINERTYPE\": \"cans\"}]}}\n"
     ]
    }
   ],
   "source": [
    "input_text = '(ORDER (PIZZAORDER (NUMBER fourteen ) (TOPPING garlic powder ) ) (DRINKORDER (NUMBER 6 ) (CONTAINERTYPE cans) (DRINKTYPE diet ice teas ) ) )'\n",
    "\n",
    "result = parse_order(input_text)\n",
    "print(json.dumps(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ORDER\": {\"PIZZAORDER\": [{\"NUMBER\": \"fourteen\", \"SIZE\": null, \"STYLE\": null, \"AllTopping\": [{\"NOT\": false, \"Quantity\": null, \"Topping\": \"garlic powder\"}]}], \"DRINKORDER\": [{\"NUMBER\": \"6\", \"VOLUME\": null, \"DRINKTYPE\": \"diet ice teas\", \"CONTAINERTYPE\": null}]}}\n"
     ]
    }
   ],
   "source": [
    "input_text = '(ORDER (PIZZAORDER (TOPPING garlic powder ) (NUMBER fourteen ) ) (DRINKORDER (NUMBER 6 ) (DRINKTYPE diet ice teas ) ) )'\n",
    "\n",
    "result = parse_order(input_text)\n",
    "print(json.dumps(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save TOP-DECOUPLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract parsed data from the DataFrame\n",
    "parsed_data = []\n",
    "for _, row in df.iterrows():\n",
    "    if \"train.TOP-DECOUPLED\" in row:\n",
    "        parsed_entry = parse_order(row[\"train.TOP-DECOUPLED\"])\n",
    "        parsed_data.append(parsed_entry)\n",
    "\n",
    "# Save the parsed data to a file\n",
    "output_path = \"../dataset/parsed_order_data.json\"\n",
    "with open(output_path, \"w\") as parsed_file:\n",
    "    json.dump(parsed_data, parsed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del src_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "del dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del X_test_processed\n",
    "del X_train_processed\n",
    "del y_test_processed\n",
    "del y_train_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train.TOP-DECOUPLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Step 1: Open the JSON file containing multiple objects\n",
    "with open('../dataset/parsed_order_data.json', 'r') as file:\n",
    "    # Step 2: Read each JSON object (assuming each JSON object is on a new line)\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())  # Parse the JSON object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn TOP into TOP-DECOUPLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Remove special characters and unnecessary symbols from text.\n",
    "    \"\"\"\n",
    "    #stop_words = set(stopwords.words('english')) # takes much time\n",
    "    stop_words = [\n",
    "    \"an\", \"the\", \"and\", \"or\", \"but\", \"if\", \"in\",  \"at\", \n",
    "    \"by\", \"from\", \"to\", \"of\", \"for\", \"this\", \"that\", \"those\", \"these\", \n",
    "    \"can\", \"could\", \"would\", \"should\", \"will\", \"might\", \"may\", \"i\", \"you\", \n",
    "    \"we\", \"he\", \"she\", \"it\", \"they\", \"is\", \"are\", \"was\", \"were\", \"be\", \n",
    "    \"been\", \"have\", \"has\", \"had\", \"please\",\"'\", \"d\",\"without\", \"with\", \"any\", \"s\", \"no\"\n",
    "    ]#### i'd with without no \"on\", \"with\", ,    \"a\", \n",
    "    custom_remove = [\n",
    "    r\"please\",\n",
    "    r\"thank\\s?you\", \n",
    "    r\"kindly\", \n",
    "    r\"just\", \n",
    "    r\"really\",\n",
    "    r\"actually\",\n",
    "    r\"like\",\n",
    "    r\"want\",\n",
    "    r\"pizza\",\n",
    "    r\"pie\",\n",
    "    r\"need\",\n",
    "    r\"hold\",\n",
    "    r\"also\",\n",
    "    r\"hate\",\n",
    "    r\"avoid\",\n",
    "    ]\n",
    "    # Remove special characters\n",
    "    #text = re.sub(r\"[^\\w\\s]\", \" \", text)  # Remove punctuation and special characters\n",
    "    # Remove \"i'd\"\n",
    "    text = re.sub(r\"\\bi'd\\b\", \"\", text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    # Remove stopwords\n",
    "    if stop_words:\n",
    "        text = \" \".join([word for word in text.split() if word.lower() not in stop_words])\n",
    "    # Remove custom characters or substrings\n",
    "    if custom_remove:\n",
    "        for pattern in custom_remove:\n",
    "            text = re.sub(pattern, \"\", text)\n",
    "    # Remove extra whitespace (convert any 2 or more spaces into 1)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP = df['train.TOP'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (STYLE vegetarian ) ) )'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOP = TOP.apply(clean_text)## twice\n",
    "TOP[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECOUPLED = df['train.TOP-DECOUPLED'].apply(clean_text)\n",
    "DECOUPLED[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DECOUPLED[2] == TOP[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure Transformation works right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct 2456446, Total 2456446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sequences = 0\n",
    "correct_sequences = 0\n",
    "\n",
    "for src,tgt in zip(TOP, DECOUPLED):\n",
    "\n",
    "    if src == tgt:\n",
    "        # print(pred)\n",
    "        # print(tgt)\n",
    "        correct_sequences += 1\n",
    "    else:\n",
    "        print(src)\n",
    "        print(tgt)\n",
    "        \n",
    "    total_sequences += 1\n",
    "\n",
    "print(f\"Correct {correct_sequences}, Total {total_sequences}\")\n",
    "sequence_accuracy = correct_sequences / total_sequences if total_sequences > 0 else 0\n",
    "sequence_accuracy * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
