{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "ENTITY_KEYS = {\n",
    "    \"NUMBER\", \"SIZE\", \"STYLE\", \"TOPPING\", \"COMPLEX_TOPPING\", \"QUANTITY\",\n",
    "    \"VOLUME\", \"DRINKTYPE\", \"CONTAINERTYPE\"\n",
    "}\n",
    "ORDER_KEYS = {\"PIZZAORDER\", \"DRINKORDER\"}\n",
    "\n",
    "def tokenize(s):\n",
    "    tokens = re.findall(r'\\(|\\)|[^\\s()]+', s)\n",
    "    return tokens\n",
    "\n",
    "def tokenize2(s):\n",
    "    # just split by space\n",
    "    return s.split()\n",
    "\n",
    "def parse_tokens(tokens):\n",
    "    stack = []\n",
    "    current_list = []\n",
    "    for token in tokens:\n",
    "        if token == '(':\n",
    "            stack.append(current_list)\n",
    "            current_list = []\n",
    "        elif token == ')':\n",
    "            finished = current_list\n",
    "            current_list = stack.pop()\n",
    "            current_list.append(finished)\n",
    "        else:\n",
    "            current_list.append(token)\n",
    "    return current_list\n",
    "def extract_orders(structure, order_index=1):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    if not isinstance(structure, list) or len(structure) == 0:\n",
    "        return results, order_index\n",
    "\n",
    "    first = structure[0]\n",
    "    if isinstance(first, list):\n",
    "        for elem in structure:\n",
    "            sub_results, order_index = extract_orders(elem, order_index)\n",
    "            results.extend(sub_results)\n",
    "        return results, order_index\n",
    "\n",
    "    if isinstance(first, str) and first in ORDER_KEYS:\n",
    "        order_type = \"PIZZAORDER\" if first == \"PIZZAORDER\" else \"DRINKORDER\"\n",
    "        current_order_sequence = order_index\n",
    "        order_index += 1\n",
    "        content_tokens = []\n",
    "        for elem in structure[1:]:\n",
    "            content_tokens.extend(collect_tokens(elem))\n",
    "        for tok in content_tokens:\n",
    "            results.append((tok, order_type, current_order_sequence))\n",
    "\n",
    "        return results, order_index\n",
    "    else:\n",
    "        for elem in structure:\n",
    "            sub_results, order_index = extract_orders(elem, order_index)\n",
    "            results.extend(sub_results)\n",
    "        return results, order_index\n",
    "def collect_tokens(node):\n",
    "    collected = []\n",
    "    if isinstance(node, list):\n",
    "        for sub in node:\n",
    "            sub_tokens = collect_tokens(sub)\n",
    "            collected.extend(sub_tokens)\n",
    "    else:\n",
    "        if node not in [\"(\", \")\"] and not is_structural_key(node):\n",
    "            collected.append(node)\n",
    "    return collected\n",
    "\n",
    "def is_structural_key(token):\n",
    "    return token in [\n",
    "        \"ORDER\",\"PIZZAORDER\",\"DRINKORDER\",\"NUMBER\",\"SIZE\",\"STYLE\",\"TOPPING\",\n",
    "        \"COMPLEX_TOPPING\",\"QUANTITY\",\"VOLUME\",\"DRINKTYPE\",\"CONTAINERTYPE\",\"NOT\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 11, 11, 11, 11, 11, 11, 0, 22, 22, 22, 22]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def transform_to_labels(input_array):\n",
    "    labeled_numbers = []\n",
    "\n",
    "    for _, label, sequence in input_array:\n",
    "        # Compute the numerical label\n",
    "        if label == 'O' and sequence is None:\n",
    "            numerical_label = 0  # Neutral/irrelevant\n",
    "        elif label == 'PIZZAORDER':\n",
    "            numerical_label = 10 + sequence  # Unique range for pizza orders\n",
    "        elif label == 'DRINKORDER':\n",
    "            numerical_label = 20 + sequence  # Unique range for drink orders\n",
    "        else:\n",
    "            numerical_label = 0  # Default fallback\n",
    "\n",
    "        labeled_numbers.append(numerical_label)\n",
    "\n",
    "    return labeled_numbers\n",
    "\n",
    "transform_to_labels(input_label_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_labeling(labels):\n",
    "    label_map = {\n",
    "        \"B-PIZZAORDER\": 1,\n",
    "        \"I-PIZZAORDER\": 2,\n",
    "        \"B-DRINKORDER\": 3,\n",
    "        \"I-DRINKORDER\": 4,\n",
    "        \"O\": 5\n",
    "    }\n",
    "\n",
    "    bio_labels = []\n",
    "    seen_numbers = set()  # Track already encountered order numbers\n",
    "\n",
    "    for label in labels:\n",
    "        if label == 0:\n",
    "            # Neutral/irrelevant token\n",
    "            bio_labels.append(label_map[\"O\"])\n",
    "        else:\n",
    "            # Determine if it's a PizzaOrder or DrinkOrder\n",
    "            if 10 <= label < 20:\n",
    "                label_type = \"PIZZAORDER\"\n",
    "            elif 20 <= label < 30:\n",
    "                label_type = \"DRINKORDER\"\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid label encountered: {label}\")\n",
    "\n",
    "            # Assign B- or I- based on first or repeated appearance\n",
    "            if label not in seen_numbers:\n",
    "                bio_label = label_map[f\"B-{label_type}\"]\n",
    "                seen_numbers.add(label)\n",
    "            else:\n",
    "                bio_label = label_map[f\"I-{label_type}\"]\n",
    "\n",
    "            bio_labels.append(bio_label)\n",
    "\n",
    "    return bio_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model1_training_data(input_file: str, output_file: str):\n",
    "\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            record = json.loads(line)\n",
    "            src = record[\"train.SRC\"]\n",
    "            top = record[\"train.TOP\"]\n",
    "\n",
    "            labeled_input = label_input(src, top)\n",
    "            numerical_labels = transform_to_labels(labeled_input)\n",
    "            bio_labels = transform_labeling(numerical_labels)\n",
    "\n",
    "            training_instance = {\n",
    "                \"text\": src,\n",
    "                \"labels\": bio_labels\n",
    "            }\n",
    "\n",
    "            outfile.write(json.dumps(training_instance) + \"\\n\")\n",
    "\n",
    "# File paths\n",
    "input_file = \"../dataset3/PIZZA_train.json\"\n",
    "output_file = \"../dataset3/train_data_model1.json\"\n",
    "\n",
    "# Generate the training data\n",
    "create_model1_training_data(input_file,output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'O'),\n",
       " ('want', 'O'),\n",
       " ('a', 'B-NUMBER'),\n",
       " ('pizza', 'O'),\n",
       " ('with', 'O'),\n",
       " ('pesto', 'B-TOPPING'),\n",
       " ('and', 'O'),\n",
       " ('mushrooms', 'B-TOPPING'),\n",
       " ('but', 'O'),\n",
       " ('no', 'O'),\n",
       " ('pineapple', 'B-NEG_TOPPING')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import json\n",
    "import re\n",
    "\n",
    "def tokenize(s):\n",
    "    # Extract tokens: parentheses or sequences of non-whitespace, non-parenthesis characters.\n",
    "    tokens = re.findall(r'\\(|\\)|[^\\s()]+', s)\n",
    "    return tokens\n",
    "\n",
    "def parse_tokens(tokens):\n",
    "    # Parse tokens into a nested list structure\n",
    "    stack = []\n",
    "    current_list = []\n",
    "    for token in tokens:\n",
    "        if token == '(':\n",
    "            stack.append(current_list)\n",
    "            current_list = []\n",
    "        elif token == ')':\n",
    "            finished = current_list\n",
    "            current_list = stack.pop()\n",
    "            current_list.append(finished)\n",
    "        else:\n",
    "            current_list.append(token)\n",
    "    return current_list\n",
    "\n",
    "# Keys that indicate entities we want to label\n",
    "ENTITY_KEYS = {\n",
    "    \"NUMBER\", \"SIZE\", \"STYLE\", \"TOPPING\", \"COMPLEX_TOPPING\", \"QUANTITY\",\n",
    "    \"VOLUME\", \"DRINKTYPE\", \"CONTAINERTYPE\"\n",
    "}\n",
    "\n",
    "# Keys that indicate higher-level structures (orders)\n",
    "ORDER_KEYS = {\"PIZZAORDER\", \"DRINKORDER\"}\n",
    "\n",
    "def label_entity_tokens(values, entity_type, negated=False):\n",
    "    \"\"\"\n",
    "    Given a list of tokens (values) inside an entity,\n",
    "    return a list of (token, label) pairs with B-/I- tagging.\n",
    "\n",
    "    entity_type: e.g. \"NUMBER\", \"TOPPING\", etc.\n",
    "    negated: boolean, if True we prepend \"NEG_\" to the entity_type\n",
    "    \"\"\"\n",
    "    if negated:\n",
    "        prefix = \"NEG_\"\n",
    "    else:\n",
    "        prefix = \"\"\n",
    "\n",
    "    labels = []\n",
    "    for i, val in enumerate(values):\n",
    "        tag = \"B-\" + prefix + entity_type if i == 0 else \"I-\" + prefix + entity_type\n",
    "        labels.append((val, tag))\n",
    "    return labels\n",
    "\n",
    "def flatten_nested_structure(structure, order_context=None, negated=False):\n",
    "    \"\"\"\n",
    "    Recursively descend through the parsed structure and produce (token, label) pairs.\n",
    "    All tokens in structure are from the same tokenization as the original input.\n",
    "\n",
    "    order_context: tracks if we are inside PIZZAORDER or DRINKORDER\n",
    "    negated: tracks if we are inside a NOT block\n",
    "    \"\"\"\n",
    "    if not isinstance(structure, list):\n",
    "        # It's a single token (string)\n",
    "        # If it's not an entity value token, it's just structure or unknown => O\n",
    "        # We'll label it as O\n",
    "        return [(structure, \"O\")]\n",
    "\n",
    "    # structure is a list\n",
    "    # The first element might be a key like ORDER, PIZZAORDER, NUMBER, etc., or might be nested.\n",
    "    if len(structure) == 0:\n",
    "        return []\n",
    "\n",
    "    first = structure[0]\n",
    "    if isinstance(first, list):\n",
    "        # This means we don't have a key at the start; just nested lists.\n",
    "        # Flatten them recursively.\n",
    "        result = []\n",
    "        for elem in structure:\n",
    "            result.extend(flatten_nested_structure(elem, order_context=order_context, negated=negated))\n",
    "        return result\n",
    "    else:\n",
    "        # first is a token (string)\n",
    "        key = first\n",
    "        \n",
    "        if key == \"VOLUME\":\n",
    "            key = \"SIZE\"\n",
    "\n",
    "        if key == \"ORDER\":\n",
    "            # Just go through its children\n",
    "            result = [(key, \"O\")]\n",
    "            for elem in structure[1:]:\n",
    "                result.extend(flatten_nested_structure(elem, order_context=None, negated=False))\n",
    "            return result\n",
    "\n",
    "        elif key in ORDER_KEYS:\n",
    "            # Entering a pizza or drink order. We label the key itself as O.\n",
    "            # Inside this, we find its fields.\n",
    "            new_order_context = key  # \"PIZZAORDER\" or \"DRINKORDER\"\n",
    "            result = [(key, \"O\")]\n",
    "            for elem in structure[1:]:\n",
    "                result.extend(flatten_nested_structure(elem, order_context=new_order_context, negated=negated))\n",
    "            return result\n",
    "\n",
    "        elif key == \"NOT\":\n",
    "            # Negation block. We set negated=True inside this.\n",
    "            result = [(key, \"O\")]\n",
    "            for elem in structure[1:]:\n",
    "                result.extend(flatten_nested_structure(elem, order_context=order_context, negated=True))\n",
    "            return result\n",
    "\n",
    "        elif key in ENTITY_KEYS:\n",
    "            # This is an entity. Extract its values (non-list tokens).\n",
    "            # Example: (NUMBER one), (TOPPING cheese), (STYLE thin crust)\n",
    "            # We'll consider everything after key that is a token as part of this entity's value.\n",
    "            result = [(key, \"O\")]\n",
    "            entity_tokens = []\n",
    "            for elem in structure[1:]:\n",
    "                if isinstance(elem, list):\n",
    "                    # Complex entity may have nested (e.g. COMPLEX_TOPPING)\n",
    "                    # Flatten it and extract from subentities\n",
    "                    sub_result = flatten_nested_structure(elem, order_context=order_context, negated=negated)\n",
    "                    # sub_result might contain multiple tokens. They are already labeled, but we want them labeled as part of this entity.\n",
    "                    # Actually, for COMPLEX_TOPPING, we have QUANTITY and TOPPING inside it.\n",
    "                    # It's safer to just pass through and let sub-entities handle their own labeling.\n",
    "                    result.extend(sub_result)\n",
    "                else:\n",
    "                    # It's a direct token value\n",
    "                    entity_tokens.append(elem)\n",
    "\n",
    "            # If entity_tokens are present directly under this key, label them:\n",
    "            if entity_tokens:\n",
    "                # The entity_type should reflect the key.\n",
    "                # For COMPLEX_TOPPING, we actually break it down into QUANTITY and TOPPING subfields,\n",
    "                # but if there's a direct token (there shouldn't be normally), treat it similarly.\n",
    "                # Usually COMPLEX_TOPPING breaks down into more entities. If so, entity_tokens here might be empty.\n",
    "                entity_type = key\n",
    "                # label these entity tokens according to entity_type\n",
    "                labeled = label_entity_tokens(entity_tokens, entity_type, negated=negated)\n",
    "                result.extend(labeled)\n",
    "\n",
    "            return result\n",
    "\n",
    "        else:\n",
    "            # This is not a recognized key. It's probably a token or extra word not fitting into a known entity.\n",
    "            # Label as O.\n",
    "            result = [(key, \"O\")]\n",
    "            for elem in structure[1:]:\n",
    "                result.extend(flatten_nested_structure(elem, order_context=order_context, negated=negated))\n",
    "            return result\n",
    "\n",
    "\n",
    "def label_input(text):\n",
    "    tokens = tokenize(text)\n",
    "    parsed = parse_tokens(tokens)\n",
    "\n",
    "    # Flatten and label\n",
    "    labeled = []\n",
    "    for elem in parsed:\n",
    "        labeled.extend(flatten_nested_structure(elem, order_context=None, negated=False))\n",
    "    \n",
    "    # remove all tuples where the first element is a ENTITY_KEY or ORDER/PizzaOrder/DrinkOrder\n",
    "    labeled = [x for x in labeled if x[0] not in ENTITY_KEYS and x[0] not in ORDER_KEYS and x[0] != \"ORDER\" and x[0] != \"NOT\"]\n",
    "\n",
    "    return labeled\n",
    "\n",
    "# Example:\n",
    "input_str = \"(ORDER i want (PIZZAORDER (NUMBER a ) pizza with (TOPPING pesto ) and (TOPPING mushrooms ) but no (NOT (TOPPING pineapple ) ) ) )\"\n",
    "labeled_output = label_input(input_str)\n",
    "labeled_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_KEYS = {\n",
    "    \"NUMBER\", \"SIZE\", \"STYLE\", \"TOPPING\", \"COMPLEX_TOPPING\", \"QUANTITY\",\n",
    "    \"VOLUME\", \"DRINKTYPE\", \"CONTAINERTYPE\"\n",
    "}\n",
    "\n",
    "# Define a mapping for entity keys to numerical labels\n",
    "LABEL_MAP = {\n",
    "    'B-DRINKTYPE': 1, 'I-DRINKTYPE': 2,\n",
    "    'B-SIZE': 3, 'I-SIZE': 4,  # Treats SIZE and VOLUME as the same\n",
    "    'B-NUMBER': 5, 'I-NUMBER': 6,\n",
    "    'B-CONTAINERTYPE': 7, 'I-CONTAINERTYPE': 8,\n",
    "    'B-COMPLEX_TOPPING': 9, 'I-COMPLEX_TOPPING': 10,\n",
    "    'B-TOPPING': 11, 'I-TOPPING': 12,\n",
    "    'B-NEG_TOPPING': 13, 'I-NEG_TOPPING': 14,\n",
    "    'B-NEG_STYLE': 15, 'I-NEG_STYLE': 16,\n",
    "    'B-STYLE': 17, 'I-STYLE': 18,\n",
    "    'B-QUANTITY': 19, 'I-QUANTITY': 20,\n",
    "    'O': 21\n",
    "}\n",
    "\n",
    "def transform_to_labels(labeled_output):\n",
    "    numerical_labels = [LABEL_MAP.get(label, LABEL_MAP[\"O\"]) for _, label in labeled_output]\n",
    "    return numerical_labels\n",
    "\n",
    "\n",
    "def create_model2_training_data(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            record = json.loads(line)\n",
    "            src_text = record[\"train.SRC\"]\n",
    "            src_top = record[\"train.TOP\"]\n",
    "            labeled_output = label_input(src_top)\n",
    "            numerical_labels = transform_to_labels(labeled_output)\n",
    "            training_instance = {\n",
    "                \"text\": src_text,\n",
    "                \"labels\": numerical_labels\n",
    "            }\n",
    "            outfile.write(json.dumps(training_instance) + \"\\n\")\n",
    "\n",
    "# Paths to the input and output files\n",
    "input_file = \"../dataset3/PIZZA_train.json\"\n",
    "output_file = \"../dataset3/PIZZA_train_model2.json\"\n",
    "\n",
    "# Process the data\n",
    "create_model2_training_data(input_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
